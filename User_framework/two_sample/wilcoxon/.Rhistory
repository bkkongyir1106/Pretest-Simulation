)
}
return(results_by_dist)
}
# -----------------------------------------------------------------------------
# power vs type I error function to show optimal alpha values in title
# -----------------------------------------------------------------------------
plot_power_type1_results_optimal <- function(combined_power, combined_type1, optimal_alphas, ds_test_methods = c("test_1", "test_2", "adaptive"), distributions = c("Non-normal", "Normal"), sizes, alpha,filename = NULL, width = 7, height = 6) {
# plot characters
plot_colors <- c("red", "blue", "green")
method_shapes <- c(19, 17, 15)
method_names <- ds_test_methods
opened <- FALSE
if (!is.null(filename)) {
pdf(filename, width = width, height = height)
opened <- TRUE
}
layout(matrix(c(1,2, 3,4, 5,5), nrow = 3, byrow = TRUE), heights = c(1, 1, 0.25))
op <- par(mar = c(2.6, 3.2, 1.2, 0.8), oma = c(0, 0, 1.2, 0), mgp = c(1.6, 0.45, 0), tcl = -0.2, xaxs = "r", yaxs = "r", cex.axis = 0.75, cex.lab = 0.75)
on.exit({
par(op)
if (opened) dev.off()
}, add = TRUE)
cex.main <- 0.7
xr <- range(sizes, finite = TRUE); xpad <- 0.02 * diff(xr)
xlim_pad <- c(xr[1] - xpad, xr[2] + xpad)
# Add optimal alpha values to the plot
alpha_text <- paste("Optimal alpha:", paste(round(optimal_alphas, 3), collapse = ", "))
for (dist in distributions) {
dist_data <- subset(combined_power, Distribution == dist)
plot(NA, xlim = xlim_pad, ylim = c(0, 1.01), xlab = "Sample Size", ylab = "Power", main = paste("Power -", dist), cex.main = cex.main, font.main = 1)
for (j in seq_along(method_names)) {
method <- method_names[j]
lines(dist_data$n, dist_data[[method]], type = "b", col = plot_colors[j], pch = method_shapes[j], lwd = 2)
}
abline(h = 0.8, col = "gray50", lty = 2, lwd = 1.2)
}
for (dist in distributions) {
dist_data <- subset(combined_type1, Distribution == dist)
ymax <- max(dist_data[, method_names], na.rm = TRUE)
ypad <- 0.02 * ymax
plot(NA, xlim = xlim_pad, ylim = c(0, ymax + max(ypad, 1e-6)), xlab = "Sample Size", ylab = "Type I Error", main = paste("Type I Error -", dist), cex.main = cex.main, font.main = 1)
for (j in seq_along(method_names)) {
method <- method_names[j]
lines(dist_data$n, dist_data[[method]], type = "b", col = plot_colors[j], pch = method_shapes[j], lwd = 2)
}
abline(h = alpha, col = "gray50", lty = 3, lwd = 1.2)
}
par(mar = c(0.2, 0.2, 0.2, 0.2)); plot.new()
legend("center", legend = method_names, col = plot_colors, title = "Methods", pch = method_shapes, lwd = 2, horiz = TRUE, bty = "n", cex = 0.75)
# show optimal alpha values on title
mtext(
sprintf("Comparison of Test Methods Across Sample Sizes (Optimal alpha by n: %s)", paste(round(optimal_alphas, 3), collapse = ", ")), side = 3, outer = TRUE, line = 0.35, cex = 0.75
)
}
# ----------------------------------------------------------------------------
# calculate power for each effect size
perform_ds_power_by_effect <- function(
fixed_n            = 10,
effect_sizes       = c(0.1, 0.2, 0.3, 0.5, 1.0),
distributions      = c("Non-normal", "Normal"),
Nsim               = Nsim,
alpha              = alpha,
gen_data           = gen_data,
get_parameters     = get_parameters,
fn_to_get_norm_obj = fn_to_get_norm_obj,
fn_for_norm_test   = normality_test,
fn_for_ds_test_1   = fn_for_ds_test_1,
fn_for_ds_test_2   = fn_for_ds_test_2,
norm_test_method   = norm_test_method,
ds_test_methods    = ds_test_methods,
alpha_pre          = alpha_pre,
...
) {
ds_test_methods <- match.arg(ds_test_methods, several.ok = TRUE)
results_by_dist <- list()
for (dist in distributions) {
cat("\n=== Running POWER simulation for distribution:", dist, "with fixed n =", fixed_n, "===\n")
results_power <- list()
timing <- list()
pval_storage  <- list(H1 = list())
for (method in ds_test_methods) {
cat("Running method:", method, "\n")
pow_vec <- numeric(length(effect_sizes))
names(pow_vec) <- paste0("d=", effect_sizes)
pval_storage$H1[[method]] <- vector("list", length(effect_sizes))
pb <- txtProgressBar(min = 0, max = length(effect_sizes), style = 3)
t0 <- Sys.time()
for (i in seq_along(effect_sizes)) {
d <- effect_sizes[i]
rej_H1 <- 0L
p_H1 <- numeric(Nsim)
for (sim in seq_len(Nsim)) {
paras_H1 <- get_parameters(fixed_n, effect_size = d, dist = dist)
if (method == "test_1") {
p1 <- fn_for_ds_test_1(do.call(gen_data, paras_H1))$p.value
} else if (method == "test_2") {
p1 <- fn_for_ds_test_2(do.call(gen_data, paras_H1))$p.value
} else {
p1 <- ds_test_function(
gen_data = gen_data, get_parameters = get_parameters,
fn_to_get_norm_obj = fn_to_get_norm_obj,
fn_for_norm_test   = fn_for_norm_test,
fn_for_ds_test_1   = fn_for_ds_test_1,
fn_for_ds_test_2   = fn_for_ds_test_2,
paras = paras_H1, alpha = alpha,
norm_test_method = norm_test_method, alpha_pre = alpha_pre, ...
)
}
p_H1[sim] <- p1; if (p1 < alpha) rej_H1 <- rej_H1 + 1L
}
pow_vec[i] <- rej_H1 / Nsim
pval_storage$H1[[method]][[i]] <- p_H1
setTxtProgressBar(pb, i)
}
close(pb)
timing[[method]]        <- as.numeric(difftime(Sys.time(), t0, units = "secs"))
results_power[[method]] <- pow_vec
cat("Method", method, "completed in", round(timing[[method]], 2), "seconds\n")
}
results_by_dist[[dist]] <- list(power = results_power,
pvalues = pval_storage,
timing  = timing)
}
results_by_dist
}
# -----------------------------------------------------------------------
# plot power against erffect sizes
plot_power_by_effect_size <- function(
combined_power, distributions = c("Non-normal", "Normal"),
ds_test_methods = c("test_1", "test_2", "adaptive"),
sample_sizes, effect_sizes, alpha_pre = 0.05,
filename = NULL, width = 7, height = 4
) {
plot_colors   <- c("red", "blue", "green")
method_shapes <- c(19, 17, 15)
method_names  <- ds_test_methods
par(mfrow = c(1, 2), mar = c(3.5, 3.5, 2, 1), oma = c(1, 0, 1, 0))
panel_idx <- 0
for (dist in distributions) for (n_now in sample_sizes) {
panel_idx <- panel_idx + 1
dist_data <- subset(combined_power, Distribution == dist & n == n_now)
if (!nrow(dist_data)) {
plot(NA, xlim = range(effect_sizes), ylim = c(0, 1), xlab = "", ylab = "", main = sprintf("%s (n = %d)", dist, n_now), cex.main = 0.7, cex.axis = 0.6)
title(xlab = "Effect Size", ylab = "Power", line = 2, cex.lab = 0.65)
next
}
plot(NA, xlim = range(effect_sizes, na.rm = TRUE), ylim = c(0, 1), xlab = "", ylab = "", main = sprintf("%s (n = %d)", dist, n_now), cex.main = 0.7, cex.axis = 0.6)
title(xlab = "Effect Size", ylab = "Power", line = 2, cex.lab = 0.65)
for (j in seq_along(method_names)) {
method <- method_names[j]
if (!method %in% names(dist_data)) next
ok <- is.finite(dist_data$d) & is.finite(dist_data[[method]])
if (!any(ok)) next
x <- dist_data$d[ok]
y <- dist_data[[method]][ok]
ord <- order(x)
x <- x[ord]
y <- y[ord]
lines(x, y, type = "l", col = plot_colors[j], lwd = 2)
y_at_05 <- approx(x = x, y = y, xout = 0.5, rule = 2, ties = mean)$y
points(0.5, y_at_05, pch = method_shapes[j], col = plot_colors[j], cex = 1.0)
}
abline(v = 0.5, col = "gray50", lty = 2, lwd = 1.2)
}
# Add main title closer to plots
mtext(sprintf("Power vs Effect Size by Distribution | pre-test = %.3f", alpha_pre),
outer = TRUE, side = 3, line = 0, cex = 0.75, font = 2)
# Add single legend at bottom center
par(fig = c(0, 1, 0, 1), oma = c(0, 0, 0, 0), mar = c(0, 0, 0, 0), new = TRUE)
plot(0, 0, type = "n", bty = "n", xaxt = "n", yaxt = "n")
legend("bottom",
legend = method_names,
title = "Method",
col = plot_colors,
lwd = 2,
pch = method_shapes,
bty = "n",
cex = 0.75,
xpd = TRUE,
horiz = TRUE,
inset = c(0, -0.01))
}
setwd("~/Desktop/OSU/Research/Pretest-Simulation/cluster/two_sample/wilcoxon")
## keep startup clean â€” no extra packages auto-attached
options(defaultPackages = c("datasets","utils","grDevices","graphics","stats","methods"))
Sys.setenv(R_DEFAULT_PACKAGES = "NULL")
## ====== Cluster-friendly args, working dir, and sourcing ======
args <- commandArgs(trailingOnly = TRUE)
get_arg <- function(name, default = NULL) {
i <- grep(paste0("^--", name, "="), args)
if (length(i)) sub(paste0("^--", name, "="), "", args[i[1]]) else default
}
# Working directory where the scripts live (defaults to current dir if not passed)
wd  <- get_arg("wd",  getwd())
# Output directory for all results (PDF/RData/etc.)
out <- get_arg("out", file.path(wd, "results"))
dir.create(out, showWarnings = FALSE, recursive = TRUE)
setwd(wd)
cat("Working directory:", wd,  "\n")
cat("Output directory: ", out, "\n")
# Source helper script sitting next to this file
helper <- file.path(wd, "funs_4_2s_t_vs_wilcoxon_test.R")
if (!file.exists(helper)) stop("Helper script not found: ", helper)
source(helper)
## ====== Minimal, safe PDF wrapper (closes even on error) ======
save_pdf <- function(file, width, height, plot_fun) {
grDevices::pdf(file, width = width, height = height)
on.exit(try(grDevices::dev.off(), silent = TRUE), add = TRUE)
plot_fun()
invisible(TRUE)
}
# -----------------------------------------------------------------------------
# Function to compute optimal alpha for each sample size
# -----------------------------------------------------------------------------
compute_optimal_alpha_for_sample_sizes <- function(
sample_sizes,
distributions = c("exponential", "normal"),
effect_size = 0.5,
test_alpha = 0.05,
N = 1e6,
tol_pos = 0.01,
alpha_pretest = seq(from = 0.009, to = 1, by = 0.0025)
) {
optimal_alphas <- numeric(length(sample_sizes))
names(optimal_alphas) <- paste0("n_", sample_sizes)
cat("Computing optimal alpha values for each sample size...\n")
pb <- txtProgressBar(min = 0, max = length(sample_sizes), style = 3)
for (i in seq_along(sample_sizes)) {
n <- sample_sizes[i]
# Perform analysis for this sample size
analysis_ds_tests <- perform_analysis(
N = N,
n = n,
distributions = distributions,
effect_size = effect_size,
test = "SW",
alpha_pretest = alpha_pretest,
test_alpha = test_alpha
)
# Compute metrics
metrics <- compute_roc_metrics(
error_ds_test = analysis_ds_tests$error_ds_test,
power_ds_test = analysis_ds_tests$power_ds_test,
test_alpha = test_alpha
)
# Get optimal alpha using tradeoff analysis
tradeoff_result <- plot_power_error_tradeoff(
distributions = distributions,
alpha_pretest = alpha_pretest,
metrics = metrics,
tol_pos = tol_pos
)
optimal_alphas[i] <- tradeoff_result$alpha_star
setTxtProgressBar(pb, i)
}
close(pb)
cat("\nOptimal alpha values by sample size:\n")
print(data.frame(Sample_Size = sample_sizes, Optimal_Alpha = optimal_alphas))
return(optimal_alphas)
}
# ====================================================================
# --------------- Run the simulation -------------------
run_simulation <- function(Nsim, N, test_type, distributions, tol_pos , alpha_pre) {
## Keep a small results
results <- list(
params  = list(Nsim = Nsim, N = N, test_type = test_type, distributions = distributions , alpha_pre = alpha_pre),
objects = list(),
files   = list()
)
sample_size       <- c(10, 20, 30, 40, 50)
test_alpha        <- 0.05
alpha             <- 0.05
select_norm_test  <- "SW"
effect_size       <- 0.5
norm_alpha_pre    <- seq(from = 0.0, to = 1, by = 0.05)
alpha_pretest     <- seq(from = 0.009, to = 1, by = 0.0025)
effect_sizes      <- c(0.0, 0.1, 0.2, 0.3, 0.5, 0.8, 1.0)
sig_levels        <- seq(from = 0.005, to = 1, by = 0.005)
ds_test_methods   <- c("test_1", "test_2", "adaptive")
norm_test         <- c("SW", "SF", "KS", "JB","SKEW", "DAP", "AD", "CVM")
## ---------- ROC data for normality tests ----------
roc_pval_ds_test <- fn_for_roc_curve_for_norm_test(
n = 10,
alpha_pretest = norm_alpha_pre,
H1_dist = distributions[1],
tests = norm_test,
Nsim = Nsim
)
results$objects$roc_pval_ds_test <- roc_pval_ds_test
## Plot ROC using selected tests
results$files$norm_roc <- file.path(out, paste(test_type, "_test_norm_roc_curve.pdf"))
save_pdf(results$files$norm_roc, 7, 6, function() {
selected_tests <- c("SW", "SF", "KS", "JB","SKEW", "DAP", "AD", "CVM")
plot_norm_roc_curve(
FPR = roc_pval_ds_test$FPR,
TPR = roc_pval_ds_test$TPR,
tests_to_plot = selected_tests,
alpha = roc_pval_ds_test$alpha,
dist_name = distributions[1]
)
})
# ---------- Trade-off analysis (power & Type I error) ----------
analysis_ds_tests <- perform_analysis(
N = N,
n = 10,
distributions = distributions,
effect_size = effect_size,
test = select_norm_test,
alpha_pretest = alpha_pretest,
test_alpha = test_alpha
)
results$objects$analysis_ds_tests <- analysis_ds_tests
metrics <- compute_roc_metrics(
error_ds_test = analysis_ds_tests$error_ds_test,
power_ds_test = analysis_ds_tests$power_ds_test,
test_alpha    = test_alpha
)
results$objects$metrics <- metrics
# Capture the tradeoff result to get alpha_star
results$files$tradeoff <- file.path(out, paste(test_type, "_test_tradeoff.pdf"))
tradeoff_result <- NULL
save_pdf(results$files$tradeoff, 7, 6, function() {
tradeoff_result <<- plot_power_error_tradeoff(
distributions = distributions,
alpha_pretest = alpha_pretest,
metrics = metrics,
tol_pos = tol_pos
)
})
# Save the tradeoff result and extract alpha_star
results$objects$tradeoff_result <- tradeoff_result
alpha_star <- tradeoff_result$alpha_star
results$objects$alpha_star <- alpha_star
cat("=== Selected alpha_star from tradeoff analysis:", round(alpha_star, 4), "===\n")
## ---------- Power vs Type I error ROC-style plots ----------
roc_data <- power_vs_error_roc_data(
N = Nsim,
n = 10,
distributions = distributions,
effect_size = effect_size,
alpha_pretest = alpha_star,  # Use alpha_star here
sig_levels = sig_levels
)
results$objects$roc_data <- roc_data
results$files$power_error_roc <- file.path(out, paste(test_type, "_test_power_error_roc.pdf"))
save_pdf(results$files$power_error_roc, 6, 5, function() {
power_vs_error_ROC_curve(roc_data = roc_data)
})
# -------------------------------------------------------
# ------- Main simulation: power/Type I error analysis --
# -------------------------------------------------------
# MODIFICATION 3: Use alpha_star instead of alpha_pre for main simulation
sim_output <- perform_ds_func(
sample_sizes       = sample_size,
distributions      = distributions,
Nsim               = Nsim,
alpha              = alpha,
gen_data           = gen_data,
get_parameters     = get_parameters,
fn_to_get_norm_obj = fn_to_get_norm_obj,
fn_for_norm_test   = normality_test,
fn_for_ds_test_1   = fn_for_ds_test_1,
fn_for_ds_test_2   = fn_for_ds_test_2,
norm_test_method   = select_norm_test,
ds_test_methods    = ds_test_methods,
effect_size        = effect_size,
alpha_pre          = test_alpha  # Use alpha_star here
)
results$objects$sim_output <- sim_output
## ---------- Per-distribution AUCs (printed and saved) ----------
all_auc_tables <- list()
for (dist in names(sim_output)) {
cat("\n\n=== Results for", dist, "distribution ===\n")
dist_results  <- sim_output[[dist]]
power_results <- dist_results$power
type1_results <- dist_results$type1
power_df <- list(
test_1    = power_results$test_1,
test_2 = power_results$test_2,
adaptive      = power_results$adaptive
)
TypeI_error_df <- list(
test_1    = type1_results$test_1,
test_2 = type1_results$test_2,
adaptive      = type1_results$adaptive
)
auc_power <- sapply(power_df, function(y) compute_area(sample_size, y))
auc_type1 <- sapply(TypeI_error_df, function(y) compute_area(sample_size, y))
auc_table <- data.frame(
Method    = names(auc_power),
AUC_Power = unname(auc_power),
AUC_TypeI = unname(auc_type1),
row.names = NULL
)
all_auc_tables[[dist]] <- auc_table
print(auc_table, digits = 4)
}
results$objects$auc_tables <- all_auc_tables
## ---------- Combine across distributions and plot ----------
all_power_results <- list()
all_type1_results <- list()
for (dist in names(sim_output)) {
dist_results <- sim_output[[dist]]
power_df <- data.frame(
n = sample_size,
test_1    = dist_results$power$test_1,
test_2 = dist_results$power$test_2,
adaptive      = dist_results$power$adaptive,
Distribution  = dist
)
type1_df <- data.frame(
n = sample_size,
test_1    = dist_results$type1$test_1,
test_2 = dist_results$type1$test_2,
adaptive      = dist_results$type1$adaptive,
Distribution  = dist
)
all_power_results[[dist]] <- power_df
all_type1_results[[dist]] <- type1_df
}
combined_power <- do.call(rbind, all_power_results)
combined_type1 <- do.call(rbind, all_type1_results)
results$objects$combined_power_n <- combined_power
results$objects$combined_type1_n <- combined_type1
results$files$power_type1 <- file.path(out, paste(test_type, "_power_and_error_test.pdf"))
save_pdf(results$files$power_type1, 6, 5, function() {
plot_power_type1_results(
combined_power  = combined_power,
combined_type1  = combined_type1,
ds_test_methods = ds_test_methods,
distributions   = distributions,
sizes           = sample_size,
alpha           = alpha,
alpha_pre       = alpha_star  # Use alpha_star here
)
})
## ---------- Effect-size power curves (n = 10, 30) ----------
sample_size_es <- 10
sim_power_list <- list()
for (n in sample_size_es) {
# MODIFICATION 4: Use alpha_star instead of alpha_pre for effect size analysis
sim_power_list[[as.character(n)]] <- perform_ds_power_by_effect(
fixed_n            = n,
effect_sizes       = effect_sizes,
distributions      = distributions,
Nsim               = Nsim,
alpha              = alpha,
gen_data           = gen_data,
get_parameters     = get_parameters,
fn_to_get_norm_obj = fn_to_get_norm_obj,
fn_for_norm_test   = normality_test,
fn_for_ds_test_1   = fn_for_ds_test_1,
fn_for_ds_test_2   = fn_for_ds_test_2,
norm_test_method   = select_norm_test,
ds_test_methods    = ds_test_methods,
alpha_pre          = alpha_star  # Use alpha_star here
)
}
results$objects$sim_power_list <- sim_power_list
all_power_df <- list()
for (n in names(sim_power_list)) {
for (dist in names(sim_power_list[[n]])) {
pr <- sim_power_list[[n]][[dist]]$power
all_power_df[[paste(dist, n, sep = "_")]] <- data.frame(
d             = effect_sizes,
test_1    = pr$test_1,
test_2 = pr$test_2,
adaptive      = pr$adaptive,
Distribution  = dist,
n             = as.integer(n)
)
}
}
combined_power_effect <- do.call(rbind, all_power_df)
results$objects$combined_power_effect <- combined_power_effect
# Where to save
results$files$power_by_effect <- file.path(out, paste0(test_type, "_power_by_effect.pdf"))
# Open device with desired size, plot, then close
pdf(results$files$power_by_effect, width = 7, height = 4)
plot_power_by_effect_size(
combined_power_effect,
distributions   = distributions,
ds_test_methods = ds_test_methods,
sample_sizes    = sample_size_es,
effect_sizes    = effect_sizes,
alpha_pre       = alpha_star        # use alpha_star here
)
dev.off()
## ---------- Save compact results + full workspace ----------
rdata_results <- file.path(out, paste0(test_type, "_results.RData"))
save(results, file = rdata_results)
rdata_workspace <- file.path(out, paste0(test_type, "_workspace.RData"))
save.image(rdata_workspace)
# Final summary
cat("\n=== SIMULATION COMPLETE ===\n")
cat("Selected alpha_star used throughout:", round(alpha_star, 4), "\n")
cat("Tradeoff feasibility:", if(tradeoff_result$feasible) "FEASIBLE" else "FALLBACK", "\n")
cat("Worst-case positive inflation:", round(tradeoff_result$worst_case_positive_inflation, 6), "\n")
cat("Inflation values (Normal, Non-normal):",
round(tradeoff_result$inflations["normal"], 6), ",",
round(tradeoff_result$inflations["nonnormal"], 6), "\n")
invisible(results)
}
## Example call
run_simulation(
Nsim = 1e2, N = 1e3,
test_type = "two_sample_t_vs_wilcoxon",
distributions = c("exponential", "normal"),
tol_pos = 1e-2,
alpha_pre = 0.05
)
