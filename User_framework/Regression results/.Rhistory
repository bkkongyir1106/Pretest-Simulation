# We assume first column is group, second is value
grouped_samples <- split(data[[2]], data[[1]])
pvals <- sapply(grouped_samples, function(sample) {
generate_tests(sample, test = test)$p.value
})
all_normality_satisfied <- all(pvals > alpha)
}
else {
stop("Unsupported input type: must be numeric vector, list of vectors, or grouped data.")
}
return(list(p_values = pvals, normality_satisfied = all_normality_satisfied))
}
# ------------------------------------------------------------------------------
# ------------------ Downstream Test function -------------------------------
# ------------------------------------------------------------------------------
ds_test_function <- function(
gen_data = gen_data,
get_parameters = get_parameters,
fn_to_get_norm_obj = fn_to_get_norm_obj,
fn_for_norm_test = normality_test,
fn_for_ds_test_1 = fn_for_ds_test_1,
fn_for_ds_test_2 = fn_for_ds_test_2,
paras            = NULL,
alpha = 0.05,
norm_test_method = "SW",
...
) {
# generate data set. Accept parameters if provided
data <- if (!is.null(paras)) do.call(gen_data, paras) else gen_data()
# get normality test object
normality_test_object     <- fn_to_get_norm_obj(data)
normality_test_pval  <- fn_for_norm_test(data = normality_test_object, test = norm_test_method, alpha = alpha)
# choose ds test method based normality test results
if (isTRUE(normality_test_pval$normality_satisfied)) {
ds_test <- fn_for_ds_test_1(data)
} else {
ds_test<- fn_for_ds_test_2(data, ...)
}
return(ds_test$p.value)
}
# ----------------- Power/Type I error Analysis Test Function ---------------
# ----------------- Power + Type I error in one pass -----------------
perform_ds_func <- function(
sample_sizes       = c(10, 20, 30, 40, 50),
Nsim               = 1e3,
alpha              = 0.05,
gen_data           = gen_data,
get_parameters     = function(n) list(n = n),
fn_to_get_norm_obj = fn_to_get_norm_obj,
fn_for_norm_test   = normality_test,
fn_for_ds_test_1   = fn_for_ds_test_1,
fn_for_ds_test_2   = fn_for_ds_test_2,
norm_test_method   = "SW",
ds_test_methods    = c("parametric", "nonparametric", "adaptive"),
effect_size        = NULL,
...
) {
ds_test_methods <- match.arg(ds_test_methods, several.ok = TRUE)
results_power  <- list()
results_type1  <- list()
timing         <- list()
# keep both H0/H1 p-values if you want to inspect later
pval_storage <- list(H0 = list(), H1 = list())
for (method in ds_test_methods) {
cat("Running method:", method, "\n")
pow_vec <- typ1_vec <- numeric(length(sample_sizes))
names(pow_vec) <- names(typ1_vec) <- paste0("n=", sample_sizes)
# store pvals by n for this method
pval_storage$H0[[method]] <- vector("list", length(sample_sizes))
pval_storage$H1[[method]] <- vector("list", length(sample_sizes))
pb <- txtProgressBar(min = 0, max = length(sample_sizes), style = 3)
t0 <- Sys.time()
for (i in seq_along(sample_sizes)) {
n <- sample_sizes[i]
rej_H0 <- rej_H1 <- 0L
p_H0 <- p_H1 <- numeric(Nsim)
for (sim in seq_len(Nsim)) {
# Build params for H0 and H1 (same n/par; effect_size differs)
paras_H0 <- get_parameters(n, par = NULL, effect_size = c(0.0, 0.0, 0.0, 0.0, 0.0))
paras_H1 <- get_parameters(n, par = NULL, effect_size = effect_size)
dat_H0 <- if (!is.null(paras_H0)) do.call(gen_data, paras_H0) else gen_data()
dat_H1 <- if (!is.null(paras_H1)) do.call(gen_data, paras_H1) else gen_data()
# Compute p-values per method
if (method == "parametric") {
p0 <- tryCatch(fn_for_ds_test_1(dat_H0)$p.value, error = function(e) NA_real_)
p1 <- tryCatch(fn_for_ds_test_1(dat_H1)$p.value, error = function(e) NA_real_)
} else if (method == "nonparametric") {
p0 <- tryCatch(fn_for_ds_test_2(dat_H0, ...)$p.value, error = function(e) NA_real_)
p1 <- tryCatch(fn_for_ds_test_2(dat_H1, ...)$p.value, error = function(e) NA_real_)
} else { # adaptive
p0 <- tryCatch(ds_test_function(
gen_data           = gen_data,
get_parameters     = get_parameters,
fn_to_get_norm_obj = fn_to_get_norm_obj,
fn_for_norm_test   = fn_for_norm_test,
fn_for_ds_test_1   = fn_for_ds_test_1,
fn_for_ds_test_2   = fn_for_ds_test_2,
paras              = paras_H0,
alpha              = alpha,
norm_test_method   = norm_test_method,
...
), error = function(e) NA_real_)
p1 <- tryCatch(ds_test_function(
gen_data           = gen_data,
get_parameters     = get_parameters,
fn_to_get_norm_obj = fn_to_get_norm_obj,
fn_for_norm_test   = fn_for_norm_test,
fn_for_ds_test_1   = fn_for_ds_test_1,
fn_for_ds_test_2   = fn_for_ds_test_2,
paras              = paras_H1,
alpha              = alpha,
norm_test_method   = norm_test_method,
...
), error = function(e) NA_real_)
}
p_H0[sim] <- p0
p_H1[sim] <- p1
if (!is.na(p0) && p0 < alpha) rej_H0 <- rej_H0 + 1L
if (!is.na(p1) && p1 < alpha) rej_H1 <- rej_H1 + 1L
}
typ1_vec[i] <- rej_H0 / Nsim
pow_vec[i]  <- rej_H1 / Nsim
pval_storage$H0[[method]][[i]] <- p_H0
pval_storage$H1[[method]][[i]] <- p_H1
setTxtProgressBar(pb, i)
}
close(pb)
t1 <- Sys.time()
timing[[method]] <- as.numeric(difftime(t1, t0, units = "secs"))
results_type1[[method]] <- typ1_vec
results_power[[method]] <- pow_vec
cat("Method", method, "completed in", round(timing[[method]], 2), "seconds\n")
}
list(power = results_power, type1 = results_type1, pvalues = pval_storage, timing = timing)
}
# -------------------------------------------------------
# ------- Main simulation: power/Type I error analysis --
# ---- Main simulation
Nsim        <- 1e4
sizes       <- c(10, 20, 30, 40, 50)
alpha       <- 0.05
norm_test   <- "SW"
effect_size <- 0.5
ds_test_methods <- c("parametric", "nonparametric", "adaptive")
# =============================================================================
# -----------------------------------------------------------------------------
# Function to compute p-values for normality test & downstream tests
# -----------------------------------------------------------------------------
generate_pval<- function(N, n, effect_size, test = "SW", dist = "Normal", ...) {
# Initialize storage
pval_t.test_H0 <- pval_wilcox.test_H0 <- numeric(N)
pval_t.test_H1 <- pval_wilcox.test_H1 <- numeric(N)
norm_pvals_H0 <- norm_pvals_H1 <- vector("list", N)
pb <- txtProgressBar(min = 0, max = N, style = 3)
for (i in 1:N) {
# Under null hypothesis
paras_H0 <- get_parameters(n, dist = dist, effect_size = c(0.0, 0.0, 0.0, 0.0, 0.0))
data_H0 <- do.call(gen_data, paras_H0)
# Under alternative hypothesis
paras_H1 <- get_parameters(n, dist = dist, effect_size = effect_size)
data_H1 <- do.call(gen_data, paras_H1)
# Get normality test objects
normality_test_object_H0 <- fn_to_get_norm_obj(data_H0)
normality_test_object_H1 <- fn_to_get_norm_obj(data_H1)
# perform normality test
normality_test_H0 <- normality_test(normality_test_object_H0, test = test, alpha = 0.05)
normality_test_H1 <- normality_test(normality_test_object_H1, test = test, alpha = 0.05)
# Store normality p-values
norm_pvals_H0[[i]] <- normality_test_H0$p_values
norm_pvals_H1[[i]] <- normality_test_H1$p_values
# Get test p-values under null and alternative
pval_t.test_H0[i] <- fn_for_ds_test_1(data_H0)$p.value
pval_wilcox.test_H0[i] <- fn_for_ds_test_2(data_H0)$p.value
pval_t.test_H1[i] <- fn_for_ds_test_1(data_H1)$p.value
pval_wilcox.test_H1[i] <- fn_for_ds_test_2(data_H1)$p.value
setTxtProgressBar(pb, i)
}
close(pb)
return(list(
pval_t.test_H0 = pval_t.test_H0,
pval_wilcox.test_H0 = pval_wilcox.test_H0,
pval_t.test_H1 = pval_t.test_H1,
pval_wilcox.test_H1 = pval_wilcox.test_H1,
norm_pvals_H0 = norm_pvals_H0,
norm_pvals_H1 = norm_pvals_H1
))
}
# --------------- Calculate power/Type I errors for each test method --------------
perform_analysis <- function(N, n, distributions, effect_size, test, alpha_pretest, test_alpha) {
ds_test_results <- list()
error_ds_test <- list()
power_ds_test <- list()
pb_dist <- txtProgressBar(min = 0, max = length(distributions), style = 3)
for(dist_idx in seq_along(distributions)) {
dist <- distributions[dist_idx]
cat("Processing distribution:", dist, "\n")
# Store all p-values from generate_pval
ds_test_results[[dist]] <- generate_pval(N, n, effect_size = effect_size, test = "SW" , dist = dist)
# Calculate Type I error rates (under H0)
error_ds_test[[dist]] <- list(
error_t.test = mean(ds_test_results[[dist]]$pval_t.test_H0 < test_alpha),
error_wilcox.test = mean(ds_test_results[[dist]]$pval_wilcox.test_H0 < test_alpha),
# storage for adaptive test for error
adaptive_wilcox_error = numeric(length(alpha_pretest)))
# Calculate Power (under H1)
power_ds_test[[dist]] <- list(
power_t.test = mean(ds_test_results[[dist]]$pval_t.test_H1 < test_alpha),
power_wilcox.test = mean(ds_test_results[[dist]]$pval_wilcox.test_H1 < test_alpha),
# storage for adaptive test for power
adaptive_wilcox_power = numeric(length(alpha_pretest)))
pb_alpha <- txtProgressBar(min = 0, max = length(alpha_pretest), style = 3)
# compute decisions for each alpha level
for(j in seq_along(alpha_pretest)) {
alpha <- alpha_pretest[j]
# For Type I error (H0)
use_t_test_H0 <- sapply(ds_test_results[[dist]]$norm_pvals_H0, function(x) all(x > alpha))
adaptive_pvals_H0 <- ifelse(use_t_test_H0,
ds_test_results[[dist]]$pval_t.test_H0,
ds_test_results[[dist]]$pval_wilcox.test_H0)
error_ds_test[[dist]]$adaptive_wilcox_error[j] <- mean(adaptive_pvals_H0 < test_alpha)
# For Power (H1)
use_t_test_H1 <- sapply(ds_test_results[[dist]]$norm_pvals_H1, function(x) all(x > alpha))
adaptive_pvals_H1 <- ifelse(use_t_test_H1,
ds_test_results[[dist]]$pval_t.test_H1,
ds_test_results[[dist]]$pval_wilcox.test_H1)
power_ds_test[[dist]]$adaptive_wilcox_power[j] <- mean(adaptive_pvals_H1 < test_alpha)
setTxtProgressBar(pb_alpha, j)
}
close(pb_alpha)
setTxtProgressBar(pb_dist, dist_idx)
}
close(pb_dist)
return(list(
error_ds_test = error_ds_test,
power_ds_test = power_ds_test,
all_pvalues     = ds_test_results   # raw p-values saved here
))
}
# run analysis to get power and error
Nsim <- 1e3
alpha_pretest = seq(from = 0.005, to = 1, by = 0.005)
#alpha_pretest = seq(from = 0.009, to = 1, by = 0.0025)
analysis_ds_tests <- perform_analysis(
N = Nsim,
n = 10,
distributions = c("Normal", "exponential"),
effect_size = effect_size,
test = "SW",
alpha_pretest = alpha_pretest,
test_alpha = 0.05
)
suppressWarnings({
if (!requireNamespace("MASS", quietly = TRUE)) install.packages("MASS")
})
library(MASS)
# ---------- Box–Cox helper (works with nonpositive data via auto shift) ----------
.boxcox_with_shift <- function(y, x_intercept_only = TRUE, grid = seq(-2, 2, by = 0.1)) {
y <- as.numeric(y)
# Shift to strictly positive if needed
eps <- 1e-6
shift <- if (min(y) <= 0) (1 - min(y) + eps) else 0
df <- data.frame(yp = y + shift)
# Intercept-only model is fine for selecting lambda for one-sample setting
fit <- if (x_intercept_only) lm(yp ~ 1, data = df) else lm(yp ~ 1, data = df)
bc  <- MASS::boxcox(fit, lambda = grid, plotit = FALSE)
lambda <- bc$x[which.max(bc$y)]
# Transform
if (abs(lambda) < 1e-8) {
y_t <- log(df$yp)
tfun <- function(z) log(z + shift)
} else {
y_t <- (df$yp^lambda - 1)/lambda
tfun <- function(z) ((z + shift)^lambda - 1)/lambda
}
list(y_t = y_t, lambda = lambda, shift = shift, tfun = tfun)
}
# ---------- One-sample pipeline test ----------
# Returns list with decision and details.
one_sample_ttest_bc <- function(x, mu0, alpha = 0.05, shapiro_alpha = 0.05,
boxcox_grid = seq(-2, 2, by = 0.1),
alternative = c("two.sided","less","greater")) {
alternative <- match.arg(alternative)
x <- as.numeric(x)
stopifnot(length(x) >= 3L)
# Shapiro–Wilk on original scale
sw <- tryCatch(shapiro.test(x), error = function(e) NULL)
sw_p <- if (is.null(sw)) NA_real_ else sw$p.value
normal_ok <- !is.na(sw_p) && sw_p >= shapiro_alpha
if (normal_ok) {
x_use <- x
mu0_t <- mu0
method <- "t-test on original data (normality not rejected)"
lambda <- NA_real_; shift <- 0
} else {
bc <- .boxcox_with_shift(x, grid = boxcox_grid)
x_use <- bc$y_t
mu0_t <- bc$tfun(mu0)   # transform the null value to the test scale
method <- sprintf("t-test on Box–Cox transformed data (λ=%.2f, shift=%.4f)", bc$lambda, bc$shift)
lambda <- bc$lambda; shift <- bc$shift
}
tt <- t.test(x_use, mu = mu0_t, alternative = alternative, conf.level = 1 - alpha)
list(
method = method,
shapiro_p = sw_p,
reject = (tt$p.value < alpha),
p_value = tt$p.value,
t_stat = unname(tt$statistic),
df = unname(tt$parameter),
estimate_on_test_scale = mean(x_use),
mu0_on_test_scale = mu0_t,
lambda = lambda,
shift = shift
)
}
# ---------- Simulation for Type-I error (full pipeline) ----------
# Generates data with true mean = mu0 (so H0 is true), runs the pipeline, and estimates rejection rate.
simulate_type1 <- function(n, dist = c("normal","exponential"), mu0 = 0, sigma = 1,
nsim = 5000, alpha = 0.05, shapiro_alpha = 0.05,
alternative = "two.sided", seed = 123) {
set.seed(seed)
dist <- match.arg(dist)
rgen <- switch(dist,
normal     = function(n) rnorm(n, mean = mu0, sd = sigma),
exponential = function(n) { # mean = mu0 -> rate = 1/mu0
if (mu0 <= 0) stop("For exponential, mu0 must be > 0.")
rexp(n, rate = 1/mu0)
}
)
rejections <- replicate(nsim, {
x <- rgen(n)
res <- one_sample_ttest_bc(x, mu0 = mu0, alpha = alpha,
shapiro_alpha = shapiro_alpha,
alternative = alternative)
as.integer(res$reject)
})
mean(rejections)
}
# ---------- Convenience runner: Type-I error for requested ns and dists ----------
run_type1_panel <- function(n_vec = c(10,20,30,50),
dists = c("normal","exponential"),
mu0_normal = 0, sigma_normal = 1,
mu0_expon = 1,
nsim = 5000, alpha = 0.05, shapiro_alpha = 0.05,
alternative = "two.sided", seed = 123) {
out <- list()
k <- 1
for (d in dists) {
for (n in n_vec) {
if (d == "normal") {
rate <- simulate_type1(n, dist = d, mu0 = mu0_normal, sigma = sigma_normal,
nsim = nsim, alpha = alpha, shapiro_alpha = shapiro_alpha,
alternative = alternative, seed = seed + k)
out[[k]] <- data.frame(Dist = d, n = n, mu0 = mu0_normal, sigma_or_mean = sigma_normal,
nsim = nsim, alpha = alpha, TypeI = rate, check.names = FALSE)
} else {
rate <- simulate_type1(n, dist = d, mu0 = mu0_expon,
nsim = nsim, alpha = alpha, shapiro_alpha = shapiro_alpha,
alternative = alternative, seed = seed + k)
out[[k]] <- data.frame(Dist = d, n = n, mu0 = mu0_expon, sigma_or_mean = mu0_expon,
nsim = nsim, alpha = alpha, TypeI = rate, check.names = FALSE)
}
k <- k + 1
}
}
do.call(rbind, out)
}
# ----------------------- Example: run the panel -----------------------
# Normal: H0 true at mu0 = 0, sd = 1
# Exponential: H0 true at mu0 = 1 (rate = 1)
set.seed(42)
results <- run_type1_panel(
n_vec = c(10,20,30,50),
dists = c("normal","exponential"),
mu0_normal = 0, sigma_normal = 1,
mu0_expon = 1,
nsim = 5000,  # adjust for speed/precision
alpha = 0.05, shapiro_alpha = 0.05,
alternative = "two.sided"
)
suppressWarnings({
if (!requireNamespace("MASS", quietly = TRUE)) install.packages("MASS")
})
library(MASS)
# ---------- Box–Cox helper (works with nonpositive data via auto shift) ----------
.boxcox_with_shift <- function(y, grid = seq(-2, 2, by = 0.1)) {
y <- as.numeric(y)
if (!all(is.finite(y))) stop("Non-finite values in y.")
# shift to strictly positive if needed
eps <- 1e-6
shift <- if (min(y, na.rm = TRUE) <= 0) (1 - min(y, na.rm = TRUE) + eps) else 0
yp <- y + shift
dat <- data.frame(yp = yp)  # <- ensure a real data.frame with a unique name
# choose lambda via profile log-likelihood; fall back to log if profiling fails
lambda <- tryCatch({
fit <- lm(yp ~ 1, data = dat)
bc  <- MASS::boxcox(fit, lambda = grid, plotit = FALSE)
bc$x[which.max(bc$y)]
}, error = function(e) 0)
# transform
if (abs(lambda) < 1e-8) {
y_t <- log(yp)
tfun <- function(z) log(z + shift)
} else {
y_t <- (yp^lambda - 1) / lambda
tfun <- function(z) ((z + shift)^lambda - 1) / lambda
}
list(y_t = y_t, lambda = lambda, shift = shift, tfun = tfun)
}
# ---------- One-sample pipeline test ----------
# Returns list with decision and details.
one_sample_ttest_bc <- function(x, mu0, alpha = 0.05, shapiro_alpha = 0.05,
boxcox_grid = seq(-2, 2, by = 0.1),
alternative = c("two.sided","less","greater")) {
alternative <- match.arg(alternative)
x <- as.numeric(x)
stopifnot(length(x) >= 3L)
# Shapiro–Wilk on original scale
sw <- tryCatch(shapiro.test(x), error = function(e) NULL)
sw_p <- if (is.null(sw)) NA_real_ else sw$p.value
normal_ok <- !is.na(sw_p) && sw_p >= shapiro_alpha
if (normal_ok) {
x_use <- x
mu0_t <- mu0
method <- "t-test on original data (normality not rejected)"
lambda <- NA_real_; shift <- 0
} else {
bc <- .boxcox_with_shift(x, grid = boxcox_grid)
x_use <- bc$y_t
mu0_t <- bc$tfun(mu0)   # transform the null value to the test scale
method <- sprintf("t-test on Box–Cox transformed data (λ=%.2f, shift=%.4f)", bc$lambda, bc$shift)
lambda <- bc$lambda; shift <- bc$shift
}
tt <- t.test(x_use, mu = mu0_t, alternative = alternative, conf.level = 1 - alpha)
list(
method = method,
shapiro_p = sw_p,
reject = (tt$p.value < alpha),
p_value = tt$p.value,
t_stat = unname(tt$statistic),
df = unname(tt$parameter),
estimate_on_test_scale = mean(x_use),
mu0_on_test_scale = mu0_t,
lambda = lambda,
shift = shift
)
}
# ---------- Simulation for Type-I error (full pipeline) ----------
# Generates data with true mean = mu0 (so H0 is true), runs the pipeline, and estimates rejection rate.
simulate_type1 <- function(n, dist = c("normal","exponential"), mu0 = 0, sigma = 1,
nsim = 5000, alpha = 0.05, shapiro_alpha = 0.05,
alternative = "two.sided", seed = 123) {
set.seed(seed)
dist <- match.arg(dist)
rgen <- switch(dist,
normal     = function(n) rnorm(n, mean = mu0, sd = sigma),
exponential = function(n) { # mean = mu0 -> rate = 1/mu0
if (mu0 <= 0) stop("For exponential, mu0 must be > 0.")
rexp(n, rate = 1/mu0)
}
)
rejections <- replicate(nsim, {
x <- rgen(n)
res <- one_sample_ttest_bc(x, mu0 = mu0, alpha = alpha,
shapiro_alpha = shapiro_alpha,
alternative = alternative)
as.integer(res$reject)
})
mean(rejections)
}
# ---------- Convenience runner: Type-I error for requested ns and dists ----------
run_type1_panel <- function(n_vec = c(10,20,30,50),
dists = c("normal","exponential"),
mu0_normal = 0, sigma_normal = 1,
mu0_expon = 1,
nsim = 5000, alpha = 0.05, shapiro_alpha = 0.05,
alternative = "two.sided", seed = 123) {
out <- list()
k <- 1
for (d in dists) {
for (n in n_vec) {
if (d == "normal") {
rate <- simulate_type1(n, dist = d, mu0 = mu0_normal, sigma = sigma_normal,
nsim = nsim, alpha = alpha, shapiro_alpha = shapiro_alpha,
alternative = alternative, seed = seed + k)
out[[k]] <- data.frame(Dist = d, n = n, mu0 = mu0_normal, sigma_or_mean = sigma_normal,
nsim = nsim, alpha = alpha, TypeI = rate, check.names = FALSE)
} else {
rate <- simulate_type1(n, dist = d, mu0 = mu0_expon,
nsim = nsim, alpha = alpha, shapiro_alpha = shapiro_alpha,
alternative = alternative, seed = seed + k)
out[[k]] <- data.frame(Dist = d, n = n, mu0 = mu0_expon, sigma_or_mean = mu0_expon,
nsim = nsim, alpha = alpha, TypeI = rate, check.names = FALSE)
}
k <- k + 1
}
}
do.call(rbind, out)
}
# ----------------------- Example: run the panel -----------------------
# Normal: H0 true at mu0 = 0, sd = 1
# Exponential: H0 true at mu0 = 1 (rate = 1)
set.seed(42)
results <- run_type1_panel(
n_vec = c(10,20,30,50),
dists = c("normal","exponential"),
mu0_normal = 0, sigma_normal = 1,
mu0_expon = 1,
nsim = 5000,  # adjust for speed/precision
alpha = 0.05, shapiro_alpha = 0.05,
alternative = "two.sided"
)
print(results)
