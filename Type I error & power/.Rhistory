# Under null hypothesis
paras_H0 <- get_parameters(n, dist = dist, effect_size = 0)
data_H0 <- do.call(gen_data, paras_H0)
# Under alternative hypothesis
paras_H1 <- get_parameters(n, dist = dist, effect_size = effect_size)
data_H1 <- do.call(gen_data, paras_H1)
# Get normality test objects
normality_test_object_H0 <- fn_to_get_norm_obj(data_H0)
normality_test_object_H1 <- fn_to_get_norm_obj(data_H1)
# perform normality test
normality_test_H0 <- normality_test(normality_test_object_H0, test = test, alpha = 0.05)
normality_test_H1 <- normality_test(normality_test_object_H1, test = test, alpha = 0.05)
# Store normality p-values
norm_pvals_H0[[i]] <- normality_test_H0$p_values
norm_pvals_H1[[i]] <- normality_test_H1$p_values
# Get test p-values under null and alternative
pval_t.test_H0[i] <- fn_for_ds_test_1(data_H0)$p.value
pval_wilcox.test_H0[i] <- fn_for_ds_test_2(data_H0)$p.value
pval_t.test_H1[i] <- fn_for_ds_test_1(data_H1)$p.value
pval_wilcox.test_H1[i] <- fn_for_ds_test_2(data_H1)$p.value
setTxtProgressBar(pb, i)
}
close(pb)
return(list(
pval_t.test_H0 = pval_t.test_H0,
pval_wilcox.test_H0 = pval_wilcox.test_H0,
pval_t.test_H1 = pval_t.test_H1,
pval_wilcox.test_H1 = pval_wilcox.test_H1,
norm_pvals_H0 = norm_pvals_H0,
norm_pvals_H1 = norm_pvals_H1
))
}
# --------------- Calculate power/Type I errors for each test method --------------
perform_analysis <- function(N, n, distributions, effect_size, test, alpha_pretest, test_alpha) {
ds_test_results <- list()
error_ds_test <- list()
power_ds_test <- list()
pb_dist <- txtProgressBar(min = 0, max = length(distributions), style = 3)
for(dist_idx in seq_along(distributions)) {
dist <- distributions[dist_idx]
cat("Processing distribution:", dist, "\n")
# Store all p-values from generate_pval
ds_test_results[[dist]] <- generate_pval(N, n, effect_size = effect_size, test = "SW" , dist = dist)
# Calculate Type I error rates (under H0)
error_ds_test[[dist]] <- list(
error_t.test = mean(ds_test_results[[dist]]$pval_t.test_H0 < test_alpha),
error_wilcox.test = mean(ds_test_results[[dist]]$pval_wilcox.test_H0 < test_alpha),
# storage for adaptive test for error
adaptive_wilcox_error = numeric(length(alpha_pretest)))
# Calculate Power (under H1)
power_ds_test[[dist]] <- list(
power_t.test = mean(ds_test_results[[dist]]$pval_t.test_H1 < test_alpha),
power_wilcox.test = mean(ds_test_results[[dist]]$pval_wilcox.test_H1 < test_alpha),
# storage for adaptive test for power
adaptive_wilcox_power = numeric(length(alpha_pretest)))
pb_alpha <- txtProgressBar(min = 0, max = length(alpha_pretest), style = 3)
# compute decisions for each alpha level
for(j in seq_along(alpha_pretest)) {
alpha <- alpha_pretest[j]
# For Type I error (H0)
use_t_test_H0 <- sapply(ds_test_results[[dist]]$norm_pvals_H0, function(x) all(x > alpha))
adaptive_pvals_H0 <- ifelse(use_t_test_H0,
ds_test_results[[dist]]$pval_t.test_H0,
ds_test_results[[dist]]$pval_wilcox.test_H0)
error_ds_test[[dist]]$adaptive_wilcox_error[j] <- mean(adaptive_pvals_H0 < test_alpha)
# For Power (H1)
use_t_test_H1 <- sapply(ds_test_results[[dist]]$norm_pvals_H1, function(x) all(x > alpha))
adaptive_pvals_H1 <- ifelse(use_t_test_H1,
ds_test_results[[dist]]$pval_t.test_H1,
ds_test_results[[dist]]$pval_wilcox.test_H1)
power_ds_test[[dist]]$adaptive_wilcox_power[j] <- mean(adaptive_pvals_H1 < test_alpha)
setTxtProgressBar(pb_alpha, j)
}
close(pb_alpha)
setTxtProgressBar(pb_dist, dist_idx)
}
close(pb_dist)
return(list(
error_ds_test = error_ds_test,
power_ds_test = power_ds_test,
all_pvalues     = ds_test_results   # raw p-values saved here
))
}
# run analysis to get power and error
Nsim <- 1e3
alpha_pretest = seq(from = 0.005, to = 1, by = 0.005)
analysis_ds_tests <- perform_analysis(
N = Nsim,
n = 10,
distributions = c("Normal", "exponential"),
effect_size = effect_size,
test = "SW",
alpha_pretest = alpha_pretest,
test_alpha = 0.05
)
# ------------------------------------------------------------------------------
#                         Function to compute ROC-like metrics
# ------------------------------------------------------------------------------
compute_roc_metrics <- function(error_ds_test, power_ds_test, test_alpha) {
# Non-normal case
power_t_test_nonnormal <- power_ds_test[[ 2 ]]$power_t.test
adaptive_power_nonnormal <- power_ds_test[[ 2 ]]$adaptive_wilcox_power
adaptive_error_nonnormal <- error_ds_test[[ 2 ]]$adaptive_wilcox_error
EPG <- -(adaptive_power_nonnormal - power_t_test_nonnormal) # change this
EDE <- adaptive_error_nonnormal - test_alpha
# normal case
power_t_test_normal <- power_ds_test[[ 1 ]]$power_t.test
adaptive_power_normal <- power_ds_test[[ 1 ]]$adaptive_wilcox_power
adaptive_error_normal <- error_ds_test[[ 1 ]]$adaptive_wilcox_error
EPL <- power_t_test_normal - adaptive_power_normal
EIE <- adaptive_error_normal - test_alpha
# Point estimates for benchmark comparison
power_gain <- power_ds_test[[ 2 ]]$power_wilcox.test - power_ds_test[[ 2 ]]$power_t.test
power_loss <- power_ds_test[[ 1 ]]$power_t.test - power_ds_test[[ 1 ]]$power_wilcox.test
return(list(EPL = EPL,
EPG = EPG,
EIE = EIE,
EDE = EDE,
power_gain = power_gain,
power_loss = power_loss)
)
}
# Compute metrics after running analysis
metrics <- compute_roc_metrics(
error_ds_test = analysis_ds_tests$error_ds_test,
power_ds_test = analysis_ds_tests$power_ds_test,
test_alpha    = 0.05
)
# --------------------------------------------------------------------
# Power and Type I error trade-off plots
plot_power_error_tradeoff <- function(alpha_pretest, metrics, file_name = NULL) {
# if (!is.null(file_name)) pdf(file_name, width = 12, height = 10)
par(mfrow = c(2, 2))
plot(alpha_pretest,
metrics$EPL,
type = "l",
col = "blue",
lwd = 2,
ylab = "Expected Power Loss (EPL)",
xlab = expression(alpha),
main = "Expected Power Loss(Normal)")
plot(alpha_pretest,
metrics$EPG,
type = "l",
col = "red",
lwd = 2,
ylab = "Expected Power Gain (EPG)",
xlab = expression(alpha),
main = "Expected Power Gain(Exp)")
plot(alpha_pretest,
metrics$EIE,
type = "l",
col = "orange",
lwd = 2,
ylab = "Inflation of Type I Error",
xlab = expression(alpha),
main = "EI/D of Type I error (Normal)")
plot(alpha_pretest,
metrics$EDE,
type = "l",
col = "green",
lwd = 2,
ylab = "Type I Error Inflation",
xlab = expression(alpha),
main = "EI/D of Type I error (Exp)")
if (!is.null(file_name)) dev.off()
}
plot_power_error_tradeoff(
alpha_pretest = alpha_pretest,
metrics = metrics
#file_name = "comparison_power_error.pdf"
)
EPL_vs_EPG_ROC_like_curve <- function(metrics){
par(mfrow = c(1, 2))
plot(metrics$EPL,
metrics$EPG,
type = "l",
col = "blue",
lwd = 2,
ylab = "EPG",
xlab = "EPL",
main = "ROC like curve: EPG vs EPL(Exp)")
plot(metrics$EDE,
metrics$EIE,
type = "l",
col = "blue",
lwd = 2,
ylab = "EIE",
xlab = "EDE",
main = "ROC like curve: EIE vs EDE(Exp)")
}
EPL_vs_EPG_ROC_like_curve(metrics)
# --------------------------------------------------------------------
# ----------- Function to ROC curve data for downstream test ---------
generate_roc_tables <- function(N, n, distributions, effect_size, sig_levels) {
# data frames for Type I error and Power
roc_data <- data.frame()
pb <- txtProgressBar(min = 0, max = length(distributions) * length(sig_levels), style = 3)
counter <- 0
# fixed pretest alpha
alpha_pretest <- 0.05
for (dist in distributions) {
cat("Generating ROC data for:", dist, "\n")
res <- generate_pval(N, n,  effect_size, test = "SW", dist = dist)
# Convert norm_pvals_H0 from list to numeric vector
norm_pvals_H0_vec <- sapply(res$norm_pvals_H0, function(x) if(is.null(x)) NA else x)
for (alpha in sig_levels) {
# Compute Type I error (under H0)
error_t <- mean(res$pval_t.test_H0 < alpha, na.rm = TRUE)
error_w <- mean(res$pval_wilcox.test_H0 < alpha, na.rm = TRUE)
# For adaptive test
# H0 gate (Type I error)
use_t_test_H0 <- sapply(res$norm_pvals_H0, function(v) all(as.numeric(v) > alpha_pretest))
adaptive_pvals_H0 <- ifelse(use_t_test_H0, res$pval_t.test_H0, res$pval_wilcox.test_H0)
# adaptive_pvals_H0 <- ifelse(use_t_test,
#                             res$pval_t.test_H0,
#                             res$pval_wilcox.test_H0)
error_adaptive <- mean(adaptive_pvals_H0 < alpha, na.rm = TRUE)
# Compute Power (under H1)
power_t <- mean(res$pval_t.test_H1 < alpha, na.rm = TRUE)
power_w <- mean(res$pval_wilcox.test_H1 < alpha, na.rm = TRUE)
# H1 gate (Power) â€” MUST be based on H1 data
use_t_test_H1 <- sapply(res$norm_pvals_H1, function(v) all(as.numeric(v) > alpha_pretest))
adaptive_pvals_H1 <- ifelse(use_t_test_H1, res$pval_t.test_H1, res$pval_wilcox.test_H1)
# adaptive_pvals_H1 <- ifelse(use_t_test,
#                             res$pval_t.test_H1,
#                             res$pval_wilcox.test_H1)
power_adaptive <- mean(adaptive_pvals_H1 < alpha, na.rm = TRUE)
# Append results
roc_data <- rbind(roc_data,
data.frame(
Distribution = dist,
Method = "test 1(t-test)",
Alpha = alpha,
Power = power_t,
TypeIError = error_t
),
data.frame(
Distribution = dist,
Method = "test 2(Sign test)",
Alpha = alpha,
Power = power_w,
TypeIError = error_w
)
,
data.frame(
Distribution = dist,
Method = "adaptive test",
Alpha = alpha,
Power = power_adaptive,
TypeIError = error_adaptive
))
counter <- counter + 1
setTxtProgressBar(pb, counter)
}
}
close(pb)
return(roc_data)
}
# Example usage:
Nsim <- 1e3
roc_data <- generate_roc_tables(
N = Nsim,
n = 10,
distributions = c("Normal", "exponential"),
effect_size = effect_size,
sig_levels = seq(from = 0.001, to = 1, by = 0.005)
)
# --------------------- create the plots -------------------------------------
plot_power_vs_error_ROC_curve <- function(roc_data, file_name = NULL) {
#if (!is.null(file_name)) pdf(file_name, width = 12, height = 10)
par(mfrow = c(1, length(unique(roc_data$Distribution))))
methods <- unique(roc_data$Method)
colors  <- c("blue", "red", "green")
pch_vals <- c(19, 17, 18)
for (dist in unique(roc_data$Distribution)) {
plot(NA, xlim = c(0, 1),
ylim = c(0, 1),
xlab = "Type I Error",
ylab = "Power",
main = paste("ROC-like Curve (", dist, ")", sep = ""))
for (m in seq_along(methods)) {
method <- methods[m]
data_subset <- subset(roc_data, Distribution == dist & Method == method)
if (nrow(data_subset) > 0) {
lines(data_subset$TypeIError, data_subset$Power, type = "l", col = colors[m], lwd = 2, pch = pch_vals[m])
}
}
legend("bottomright", legend = methods, col = colors,
lwd = 2, pch = pch_vals, title = "Method")
}
#   dev.off()
}
plot_power_vs_error_ROC_curve(
roc_data = roc_data
#file_name = "Power_vs_TypeIError_ROC_By_Distribution.pdf"
)
## ---- Load dependencies and user functions --------------------------------
source("~/Desktop/OSU/Research/Pretest-Simulation/functions/user_defined_functions_center_median.R")
source("~/Desktop/OSU/Research/Pretest-Simulation/functions/utility.R")
setwd("~/Desktop/OSU/Research/Pretest-Simulation/Type I error & power")
suppressPackageStartupMessages({
require(foreach)
require(snow)
require(doSNOW)
require(parallel)
})
## ---- Parallel setup helpers ----------------------------------------------
par_set <- function(cores_reserve = 2) {
cores <- parallel::detectCores()
cores_use <- max(1, cores - cores_reserve)
if (Sys.info()[["sysname"]] == "Windows") {
cl <- parallel::makeCluster(cores_use)
doSNOW::registerDoSNOW(cl)
} else {
cl <- snow::makeSOCKcluster(cores_use)
doSNOW::registerDoSNOW(cl)
}
cl
}
close_cluster <- function(cl) if (!is.null(cl)) parallel::stopCluster(cl)
## ---- Test functions -------------------------------------------------------
# Bootstrap test for the mean (non-studentized)
one_sample_bootstrap_test <- function(x, mu0 = 0, B = 1000) {
T_obs <- mean(x) - mu0
x_centered <- x - mean(x) + mu0
boot_stats <- replicate(B, mean(sample(x_centered, replace = TRUE)) - mu0)
mean(abs(boot_stats) >= abs(T_obs))
}
# Sign test for the median
sign_test <- function(x, mu0 = 0) {
x0 <- x - mu0
n_valid <- sum(x0 != 0)
if (n_valid == 0) return(1)
signs <- sum(x0 > 0)
binom.test(signs, n_valid, p = 0.5)$p.value
}
## ---- Parameters -----------------------------------------------------------
Nsim         <- 1e4
alpha        <- 0.05
B            <- 1e3
effect_size  <- 0.50
distributions <- c("Normal", "uniform", "exponential", "LogNormal")
sample_size   <- c(8, 10, 15, 20, 25, 30, 50)
# define distribution parameters
rate <- 1
shape <- 2
meanlog <- 0
sdlog <- 1
## ---- Progress bar + cluster ----------------------------------------------
my_cl <- par_set(cores_reserve = 2)
on.exit(close_cluster(my_cl), add = TRUE)
ntasks <- length(sample_size) * length(distributions)
pb <- txtProgressBar(max = ntasks, style = 3)
on.exit(close(pb), add = TRUE)
progress <- function(n) setTxtProgressBar(pb, n)
opts <- list(progress = progress)
## ---- Simulation under H0 and H1 ------------------------------------------
system.time({
sim_out <- foreach(i = seq_along(sample_size),
.packages = c("stats"),
.export = c("generate_data",
"one_sample_bootstrap_test",
"sign_test",
"alpha", "B", "Nsim", "effect_size",
"rate","shape", "meanlog", "sdlog",
"distributions", "sample_size")) %:%
foreach(j = seq_along(distributions),
.options.snow = opts,
.export = character(0)) %dopar% { #don't re-export in inner loop
n    <- sample_size[i]
dist <- distributions[j]
## reproducible RNG per task
set.seed(12345 + i * 1000 + j, kind = "L'Ecuyer-CMRG")
pval_t_H0  <- pval_boot_H0 <- pval_sign_H0 <- numeric(Nsim)
pval_t_H1  <- pval_boot_H1 <- pval_sign_H1 <- numeric(Nsim)
for (rep in seq_len(Nsim)) {
x <- generate_data(n, dist)
# --- Type I error (H0) ---
pval_t_H0[rep]      <- t.test(x, mu = 0)$p.value
pval_boot_H0[rep]   <- one_sample_bootstrap_test(x, mu0 = 0, B = B)
pval_sign_H0[rep]   <- sign_test(x, mu0 = 0)
# --- Power (H1) ---
x1 <- x + effect_size
pval_t_H1[rep]      <- t.test(x1, mu = 0)$p.value
pval_boot_H1[rep]   <- one_sample_bootstrap_test(x1, mu0 = 0, B = B)
pval_sign_H1[rep]   <- sign_test(x1, mu0 = 0)
}
list(
error_t_test         = mean(pval_t_H0 < alpha),
error_bootstrap_test = mean(pval_boot_H0 < alpha),
error_sign_test      = mean(pval_sign_H0  < alpha),
power_t_test         = mean(pval_t_H1 < alpha),
power_bootstrap_test = mean(pval_boot_H1 < alpha),
power_sign_test      = mean(pval_sign_H1 < alpha)
)
}
## close cluster
close_cluster(my_cl)
})
## ---- Collect results into arrays -----------------------------------------
make_arr <- function() array(NA,
dim = c(length(sample_size), length(distributions)),
dimnames = list(sample_size, distributions))
TypeI_error_t.test         <- make_arr()
TypeI_error_bootstrap.test <- make_arr()
TypeI_error_sign.test      <- make_arr()
power_t.test               <- make_arr()
power_bootstrap.test       <- make_arr()
power_sign.test            <- make_arr()
for (i in seq_along(sample_size)) {
for (j in seq_along(distributions)) {
TypeI_error_t.test[i, j]        <- sim_out[[i]][[j]]$error_t_test
TypeI_error_bootstrap.test[i, j] <- sim_out[[i]][[j]]$error_bootstrap_test
TypeI_error_sign.test[i, j]      <- sim_out[[i]][[j]]$error_sign_test
power_t.test[i, j]               <- sim_out[[i]][[j]]$power_t_test
power_bootstrap.test[i, j]       <- sim_out[[i]][[j]]$power_bootstrap_test
power_sign.test[i, j]            <- sim_out[[i]][[j]]$power_sign_test
}
}
## ---- print tables ----------------------------------------------
cat("Type I error Rates for t-test\n");         print(TypeI_error_t.test)
cat("Type I error Rates for Bootstrap test\n"); print(TypeI_error_bootstrap.test)
cat("Type I error Rates for Sign test\n");      print(TypeI_error_sign.test)
cat("Power for t-test\n");         print(power_t.test)
cat("Power for Bootstrap test\n"); print(power_bootstrap.test)
cat("Power for Sign test\n");      print(power_sign.test)
## Shared styles
.methods <- c("t-test", "Bootstrap", "Sign")
.cols    <- c("blue", "darkorange3", "green")
.pchs    <- c(16, 17, 18)
## Generic panel plotter (used for both Type I error and Power)
plot_metric_panels <- function(sample_size, distributions, matrices_list,
methods = .methods, cols = .cols, pchs = .pchs,
main_title = "Metric vs Sample Size",
ylab = "Rate", ylim = c(0, 1),
alpha_line = NULL, legend_title = "Methods",
legend_height = 0.28) {
stopifnot(length(matrices_list) == length(methods),
length(cols) == length(methods),
length(pchs) == length(methods))
# Layout: grid of distribution panels + legend row
nD   <- length(distributions)
nrow <- ceiling(nD / 2)
ncol <- min(2, nD)
layout_mat <- rbind(
matrix(seq_len(nrow * ncol), nrow = nrow, byrow = TRUE),
rep(nrow * ncol + 1, ncol) # legend row
)
old_par <- par(no.readonly = TRUE)
on.exit(par(old_par), add = TRUE)
layout(layout_mat, heights = c(rep(1, nrow), legend_height))
par(mar = c(4, 4, 3, 1), oma = c(0, 0, 2, 0))
# Panels
for (j in seq_along(distributions)) {
plot(range(sample_size), ylim, type = "n",
xlab = "Sample size (n)", ylab = ylab, main = distributions[j])
if (!is.null(alpha_line))
abline(h = alpha_line, col = "gray50", lty = 3, lwd = 1.5)
grid(col = "lightgray", lty = "dotted")
for (m in seq_along(methods)) {
y <- matrices_list[[m]][, j]
lines(sample_size, y, type = "b", lwd = 2, col = cols[m], pch = pchs[m])
}
}
# Legend row
par(mar = c(0, 0, 0, 0))
plot.new()
legend("center", legend = methods, col = cols, pch = pchs,
lty = 1, lwd = 2, ncol = 3, bty = "n", title = legend_title, cex = 0.95)
mtext(main_title, outer = TRUE, cex = 1.2, font = 2, line = 0.2)
}
## ---------- Type I error plot ----------
plot_type1_panels <- function(sample_size, distributions, alpha,
TypeI_error_t.test, TypeI_error_bootstrap.test, TypeI_error_sign.test) {
type1_list <- list(TypeI_error_t.test,
TypeI_error_bootstrap.test,
TypeI_error_sign.test)
plot_metric_panels(sample_size, distributions, type1_list,
methods = .methods, cols = .cols, pchs = .pchs,
main_title = "Type I Error vs Sample Size",
ylab = "Type I error rate", ylim = c(0, 0.75),
alpha_line = alpha, legend_title = "Methods")
}
## ---------- Power plot ----------
plot_power_panels <- function(sample_size, distributions,
power_t.test, power_bootstrap.test, power_sign.test,
effect_size = NA) {
power_list <- list(power_t.test,
power_bootstrap.test,
power_sign.test)
ttl <- if (is.na(effect_size)) "Power vs Sample Size"
else sprintf("Power vs Sample Size (effect_size = %.2f)", effect_size)
plot_metric_panels(sample_size, distributions, power_list,
methods = .methods, cols = .cols, pchs = .pchs,
main_title = ttl, ylab = "Power", ylim = c(0, 1),
alpha_line = 0.8, legend_title = "Methods")
}
## =========================
## Draw the two figures
## =========================
# Power
pdf("One_sample_power.pdf", width = 10, height = 8)
plot_power_panels(sample_size, distributions,
power_t.test, power_bootstrap.test, power_sign.test,
effect_size = effect_size)
dev.off()
# Type I Error
pdf("One_sample_typeI_error.pdf", width = 10, height = 8)
plot_type1_panels(sample_size, distributions, alpha,
TypeI_error_t.test, TypeI_error_bootstrap.test, TypeI_error_sign.test)
dev.off()
