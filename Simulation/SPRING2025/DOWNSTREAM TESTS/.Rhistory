}
pval
}
}
# -------------------- Unified Execution Loop ------------------------------
run_analysis <- function(results_matrix, test_type) {
for (j in seq_along(distributions)) {
for (i in seq_along(sample_size)) {
n <- sample_size[i]
dist <- distributions[j]
pvals <- simulate_scenario(n, dist, N_sim, alpha, test_type, B)
results_matrix[i, j] <- mean(pvals < alpha)
# Progress tracking
cat(sprintf("Done: %s, n=%d\n", dist, n))
}
}
return(results_matrix)
}
# Initialize results matrices with clear labeling
initialize_labeled_matrix <- function(sample_sizes, distributions) {
m <- matrix(NA,
nrow = length(sample_sizes),
ncol = length(distributions),
dimnames = list(
paste0(sample_sizes),
distributions
))
return(m)
}
# Create properly labeled matrices
type_I_error_data_splitting <- initialize_labeled_matrix(sample_size, distributions)
type_I_error_two_stage <- initialize_labeled_matrix(sample_size, distributions)
bootstrap_type_I_error <- initialize_labeled_matrix(sample_size, distributions)
# -------------------- Execute All Procedures ------------------------------
type_I_error_data_splitting <- run_analysis(type_I_error_data_splitting, "data_split")
type_I_error_two_stage <- run_analysis(type_I_error_two_stage, "two_stage")
bootstrap_type_I_error <- run_analysis(bootstrap_type_I_error, "bootstrap")
# Convert to data frames with explicit dimension names
results_to_df <- function(mat) {
as.data.frame(mat) %>%
tibble::rownames_to_column("Sample Size") %>%
tidyr::pivot_longer(cols = -`Sample Size`,
names_to = "Distribution",
values_to = "Type_I_Error")
}
# Create tidy data frames
results_list <- list(
Data_Splitting = results_to_df(type_I_error_data_splitting),
Two_Stage = results_to_df(type_I_error_two_stage),
Bootstrap = results_to_df(bootstrap_type_I_error)
)
# Save both matrix and data frame versions
save(type_I_error_data_splitting, type_I_error_two_stage, bootstrap_type_I_error,
results_list,
file = "type_I_error_results_v2.RData")
# Cleanup parallel workers
stopCluster(cl)
type_I_error_data_splitting
type_I_error_two_stage
bootstrap_type_I_error
# -------------------- SETUP -------------------------------
set.seed(123)
distributions <- c("Normal", "Exponential", "Chi-Square", "LogNormal")
sample_size <- c(8, 10, 15, 20, 25, 30)
N_sim <- 1e3
alpha <- 0.05
# Initialize results matrices
initialize_matrix <- function(sample_size, distributions) {
matrix(nrow = length(sample_size), ncol = length(distributions),
dimnames = list(sample_size, distributions))
}
type_I_error_data_splitting <- initialize_matrix(sample_size, distributions)
type_I_error_two_stage <- initialize_matrix(sample_size, distributions)
bootstrap_type_I_error <- initialize_matrix(sample_size, distributions)
# -------------------- bootstrap function -------------------------------
bootstrap_one_sample <- function(x, effect_size, alpha, n_bootstrap) {
t_observed <- (mean(x) - effect_size)/(sd(x)/sqrt(length(x)))
x_centered <- x - mean(x) + effect_size
boot_stats <- replicate(n_bootstrap, {
boot_sample <- sample(x_centered, size = length(x), replace = TRUE)
(mean(boot_sample) - effect_size)/(sd(boot_sample)/sqrt(length(x)))
})
mean(abs(boot_stats) >= abs(t_observed))
}
simulate_method <- function(n, dist, N_sim, alpha, method) {
foreach(k = 1:N_sim, .combine = rbind, .packages = "stats") %dopar% {
x <- generate_data(n, dist)
pval_data_split <- NA
pval_two_stage <- NA
pval_two_stage <- NA
# Data Splitting Procedure
if(method == "data_split" || method == "all") {
split_point <- floor(n/2)
part1 <- x[1:split_point]
part2 <- x[(split_point+1):n]
shapiro_p <- shapiro.test(part1)$p.value
if(shapiro_p > alpha) {
pval_data_split <- t.test(part2, mu = 0)$p.value
} else {
pval_data_split <- bootstrap_one_sample(part2, 0, alpha, 1e4)
}
}
# Two-Stage Procedure
if(method == "two_stage" || method == "all") {
shapiro_p <- shapiro.test(x)$p.value
if(shapiro_p > alpha) {
pval_two_stage <- t.test(x, mu = 0)$p.value
} else {
pval_two_stage <- bootstrap_one_sample(x, 0, alpha, 1e4)
}
}
# Pure Bootstrap
if(method == "bootstrap" || method == "all") {
pval_two_stage <- bootstrap_one_sample(x, 0, alpha, 1e4)
}
c(data_split = pval_data_split,
two_stage = pval_two_stage,
bootstrap = pval_two_stage)
}
}
# -------------------- PARALLEL EXECUTION -------------------------------
run_analysis <- function() {
# Set up parallel backend
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)
clusterExport(cl, c("generate_data", "bootstrap_one_sample"))
tryCatch({
for (j in seq_along(distributions)) {
for (i in seq_along(sample_size)) {
n <- sample_size[i]
dist <- distributions[j]
# Run all methods simultaneously
results <- simulate_method(n, dist, N_sim, alpha, "all")
# Update all matrices
if("data_split" %in% colnames(results)) {
type_I_error_data_splitting[i,j] <- mean(results[,"data_split"] < alpha, na.rm = TRUE)
}
if("two_stage" %in% colnames(results)) {
type_I_error_two_stage[i,j] <- mean(results[,"two_stage"] < alpha, na.rm = TRUE)
}
if("bootstrap" %in% colnames(results)) {
bootstrap_type_I_error[i,j] <- mean(results[,"bootstrap"] < alpha, na.rm = TRUE)
}
cat(sprintf("Completed: %s, n=%d\n", dist, n))
}
}
}, finally = {
stopCluster(cl)
})
list(
data_splitting = type_I_error_data_splitting,
two_stage = type_I_error_two_stage,
bootstrap = bootstrap_type_I_error
)
}
# -------------------- EXECUTE & SAVE -------------------------------
results <- run_analysis()
# -------------------- SETUP -------------------------------
set.seed(123)
distributions <- c("Normal", "Exponential", "Chi-Square", "LogNormal")
sample_size <- c(8, 10, 15, 20, 25, 30)
N_sim <- 1e3
alpha <- 0.05
# Initialize results matrices
initialize_matrix <- function(sample_size, distributions) {
matrix(nrow = length(sample_size), ncol = length(distributions),
dimnames = list(sample_size, distributions))
}
type_I_error_data_splitting <- initialize_matrix(sample_size, distributions)
type_I_error_two_stage <- initialize_matrix(sample_size, distributions)
bootstrap_type_I_error <- initialize_matrix(sample_size, distributions)
# -------------------- bootstrap function -------------------------------
bootstrap_one_sample <- function(x, effect_size, alpha, n_bootstrap) {
t_observed <- (mean(x) - effect_size)/(sd(x)/sqrt(length(x)))
x_centered <- x - mean(x) + effect_size
boot_stats <- replicate(n_bootstrap, {
boot_sample <- sample(x_centered, size = length(x), replace = TRUE)
(mean(boot_sample) - effect_size)/(sd(boot_sample)/sqrt(length(x)))
})
mean(abs(boot_stats) >= abs(t_observed))
}
simulate_method <- function(n, dist, N_sim, alpha, method) {
foreach(k = 1:N_sim, .combine = rbind, .packages = "stats") %dopar% {
x <- generate_data(n, dist)
pval_data_split <- NA
pval_two_stage <- NA
pval_two_stage <- NA
# Data Splitting Procedure
if(method == "data_split" || method == "all") {
split_point <- floor(n/2)
part1 <- x[1:split_point]
part2 <- x[(split_point+1):n]
shapiro_p <- shapiro.test(part1)$p.value
if(shapiro_p > alpha) {
pval_data_split <- t.test(part2, mu = 0)$p.value
} else {
pval_data_split <- bootstrap_one_sample(part2, 0, alpha, 1e3)
}
}
# Two-Stage Procedure
if(method == "two_stage" || method == "all") {
shapiro_p <- shapiro.test(x)$p.value
if(shapiro_p > alpha) {
pval_two_stage <- t.test(x, mu = 0)$p.value
} else {
pval_two_stage <- bootstrap_one_sample(x, 0, alpha, 1e3)
}
}
# Pure Bootstrap
if(method == "bootstrap" || method == "all") {
pval_two_stage <- bootstrap_one_sample(x, 0, alpha, 1e3)
}
c(data_split = pval_data_split,
two_stage = pval_two_stage,
bootstrap = pval_two_stage)
}
}
# -------------------- PARALLEL EXECUTION -------------------------------
run_analysis <- function() {
# Set up parallel backend
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)
clusterExport(cl, c("generate_data", "bootstrap_one_sample"))
tryCatch({
for (j in seq_along(distributions)) {
for (i in seq_along(sample_size)) {
n <- sample_size[i]
dist <- distributions[j]
# Run all methods simultaneously
results <- simulate_method(n, dist, N_sim, alpha, "all")
# Update all matrices
if("data_split" %in% colnames(results)) {
type_I_error_data_splitting[i,j] <- mean(results[,"data_split"] < alpha, na.rm = TRUE)
}
if("two_stage" %in% colnames(results)) {
type_I_error_two_stage[i,j] <- mean(results[,"two_stage"] < alpha, na.rm = TRUE)
}
if("bootstrap" %in% colnames(results)) {
bootstrap_type_I_error[i,j] <- mean(results[,"bootstrap"] < alpha, na.rm = TRUE)
}
cat(sprintf("Completed: %s, n=%d\n", dist, n))
}
}
}, finally = {
stopCluster(cl)
})
list(
data_splitting = type_I_error_data_splitting,
two_stage = type_I_error_two_stage,
bootstrap = bootstrap_type_I_error
)
}
# -------------------- EXECUTE & SAVE -------------------------------
results <- run_analysis()
# Save results
save(results, file = "onesample.split_vs_2stage_type_I_errors.RData")
# Print results
print("Data Splitting Results:")
print(results$data_splitting)
print("\nTwo-Stage Results:")
print(results$two_stage)
print("\nBootstrap Results:")
print(results$bootstrap)
bootstrap_two_sample_pvalue <- function(x1, x2, alpha, n_bootstrap) {
# Observed test statistic (e.g., difference in means, t-statistic, etc.)
observed_stat <- TwoSample_test_statistic(x1, x2)
# Combine data under Hâ‚€ (no effect)
combined <- c(x1, x2)
n1 <- length(x1)
n2 <- length(x2)
# Bootstrap null distribution of the test statistic
null_stats <- replicate(n_bootstrap, {
s1 <- sample(combined, n1, replace = TRUE)
s2 <- sample(combined, n2, replace = TRUE)
TwoSample_test_statistic(s1, s2)
})
# Compute confidence interval for the null distribution (e.g., 95% CI)
ci <- quantile(null_stats, c(alpha/2, 1 - alpha/2))
# Calculate p-value as the proportion of bootstrap samples where the null statistic
# is as extreme or more extreme than the observed statistic (two-tailed)
p_value <- mean(abs(null_stats) >= abs(observed_stat))
return(list(ci = ci, p_value = p_value))
}
bootstrap_two_sample_pvalue(rnorm(10), rnorm(10), alpha = 0.05, n_bootstrap = 1000)
for(m in 1 : 100){
boot_pval[m] = bootstrap_two_sample_pvalue(rnorm(10), rnorm(10), alpha = 0.05, n_bootstrap = 1000)
}
boot_pval = c()
for(m in 1 : 100){
boot_pval[m] = bootstrap_two_sample_pvalue(rnorm(10), rnorm(10), alpha = 0.05, n_bootstrap = 1000)
}
error = mean(boot_pval < alpha)
n_sim <- 1000
alpha <- 0.05
boot_pval <- numeric(n_sim)
for (m in seq_len(n_sim)) {
x <- rnorm(10)
y <- rnorm(10)
boot_pval[m] <- bootstrap_two_sample_pvalue(x, y, alpha = 0.05, n_bootstrap = 1000)
}
boot_pval
type_I_error
mean(boot_pval < alpha)
boot_pval = c()
for(m in 1 : 100){
boot_pval[m] = bootstrap_two_sample_pvalue(rnorm(10), rnorm(10), alpha = 0.05, n_bootstrap = 1000)
}
error = mean(boot_pval < alpha)
bootstrap_two_sample_pvalue(rnorm(100), rnorm(100), alpha = 0.05, n_bootstrap = 1000)
bootstrap_two_sample_pvalue(rnorm(100), rnorm(100), alpha = 0.05, n_bootstrap = 1000)
bootstrap_two_sample_pvalue(rnorm(100), rnorm(100), alpha = 0.05, n_bootstrap = 1000)
bootstrap_two_sample <- function(x1, x2, effect_size, alpha, n_bootstrap, sample_size) {
# Initialize a vector to store the results (power or Type I error rates)
results <- numeric(length(sample_size))
# Pre-shift x2 for the alternative hypothesis
x2_shifted <- x2 + effect_size
# Combine x1 and x2 for permutation-based null sampling
combined <- c(x1, x2)
for (j in seq_along(sample_size)) {
n <- sample_size[j]
# Ensure that we can split the pooled sample into two groups of size n.
# This assumes 2*n is less than or equal to the length of combined.
if (2 * n > length(combined)) {
stop("sample_size is too large: cannot extract two groups of size n from the pooled sample")
}
# Build the null distribution using permutation-based resampling
null_stats <- replicate(n_bootstrap, {
permuted <- sample(combined, size = 2 * n, replace = FALSE)
s1 <- permuted[1:n]
s2 <- permuted[(n + 1):(2 * n)]
TwoSample_test_statistic(s1, s2)
})
# Determine the empirical two-sided critical values at significance level alpha
crit <- quantile(null_stats, probs = c(alpha / 2, 1 - alpha / 2))
# Build the alternative distribution by bootstrapping from each group separately.
alt_stats <- replicate(n_bootstrap, {
s1 <- sample(x1, size = n, replace = TRUE)
s2 <- sample(x2_shifted, size = n, replace = TRUE)
TwoSample_test_statistic(s1, s2)
})
# Calculate the proportion of alternative test statistics that fall outside the null critical values
results[j] <- mean(alt_stats < crit[1] | alt_stats > crit[2])
}
return(results)
}
# Set seed for reproducibility
set.seed(123)
# Simulate data for two groups (both drawn from N(0,1))
x1 <- rnorm(100, mean = 0, sd = 1)
x2 <- rnorm(100, mean = 0, sd = 1)
# Define bootstrap parameters
alpha <- 0.05
n_bootstrap <- 500   # Number of bootstrap replicates (increase for more precise estimates)
sample_sizes <- c(10, 20, 30)  # Different sample sizes to test
# Calculate empirical Type I error rates
type1_error <- bootstrap_two_sample(x1, x2, effect_size = 0, alpha = alpha,
n_bootstrap = n_bootstrap, sample_size = sample_sizes)
print("Estimated Type I Error Rates:")
print(type1_error)
# Using the same simulated data from above, now with a true effect of 0.5
effect_size <- 0.5
# Calculate empirical power
power_estimate <- bootstrap_two_sample(x1, x2, effect_size = effect_size, alpha = alpha,
n_bootstrap = n_bootstrap, sample_size = sample_sizes)
print("Estimated Power for Effect Size 0.5:")
print(power_estimate)
# Using the same simulated data from above, now with a true effect of 0.5
effect_size <- 0.75
# Calculate empirical power
power_estimate <- bootstrap_two_sample(x1, x2, effect_size = effect_size, alpha = alpha,
n_bootstrap = n_bootstrap, sample_size = sample_sizes)
print("Estimated Power for Effect Size 0.5:")
print(power_estimate)
# Set seed for reproducibility
set.seed(123)
# Simulate data for two groups (both drawn from N(0,1))
x1 <- rnorm(100, mean = 0, sd = 1)
x2 <- rnorm(100, mean = 0, sd = 1)
# Define bootstrap parameters
alpha <- 0.05
n_bootstrap <- 1000   # Number of bootstrap replicates (increase for more precise estimates)
sample_sizes <- c(10, 20, 30, 50)  # Different sample sizes to test
# Calculate empirical Type I error rates
type1_error <- bootstrap_two_sample(x1, x2, effect_size = 0, alpha = alpha,
n_bootstrap = n_bootstrap, sample_size = sample_sizes)
print("Estimated Type I Error Rates:")
print(type1_error)
# Using the same simulated data from above, now with a true effect of 0.5
effect_size <- 0.75
# Calculate empirical power
power_estimate <- bootstrap_two_sample(x1, x2, effect_size = effect_size, alpha = alpha,
n_bootstrap = n_bootstrap, sample_size = sample_sizes)
print("Estimated Power for Effect Size 0.5:")
print(power_estimate)
# Set seed for reproducibility
set.seed(123)
# Simulate data for two groups (both drawn from N(0,1))
x1 <- rnorm(10, mean = 0, sd = 1)
x2 <- rnorm(10, mean = 0, sd = 1)
# Define bootstrap parameters
alpha <- 0.05
n_bootstrap <- 1000   # Number of bootstrap replicates (increase for more precise estimates)
sample_sizes <- c(10, 20, 30, 50)  # Different sample sizes to test
# Calculate empirical Type I error rates
type1_error <- bootstrap_two_sample(x1, x2, effect_size = 0, alpha = alpha,
n_bootstrap = n_bootstrap, sample_size = sample_sizes)
# Set seed for reproducibility
set.seed(123)
# Simulate data for two groups (both drawn from N(0,1))
x1 <- rnorm(10, mean = 0, sd = 1)
x2 <- rnorm(10, mean = 0, sd = 1)
# Define bootstrap parameters
alpha <- 0.05
n_bootstrap <- 1000   # Number of bootstrap replicates (increase for more precise estimates)
sample_sizes <- c(10, 20, 30, 50)  # Different sample sizes to test
# Calculate empirical Type I error rates
type1_error <- bootstrap_two_sample(x1, x2, effect_size = 0, alpha = alpha,
n_bootstrap = n_bootstrap, sample_size = sample_sizes)
bootstrap_two_sample <- function(x1, x2, effect_size, alpha, n_bootstrap, sample_size) {
# Initialize a vector to store the results (power or Type I error rates)
results <- numeric(length(sample_size))
# Pre-shift x2 for the alternative hypothesis
x2_shifted <- x2 + effect_size
# Combine x1 and x2 for permutation-based null sampling
combined <- c(x1, x2)
for (j in seq_along(sample_size)) {
n <- sample_size[j]
# Ensure that we can split the pooled sample into two groups of size n.
# This assumes 2*n is less than or equal to the length of combined.
if (2 * n > length(combined)) {
stop("sample_size is too large: cannot extract two groups of size n from the pooled sample")
}
# Build the null distribution using permutation-based resampling
null_stats <- replicate(n_bootstrap, {
permuted <- sample(combined, size = 2 * n, replace = FALSE)
s1 <- permuted[1:n]
s2 <- permuted[(n + 1):(2 * n)]
TwoSample_test_statistic(s1, s2)
})
# Determine the empirical two-sided critical values at significance level alpha
crit <- quantile(null_stats, probs = c(alpha / 2, 1 - alpha / 2))
# Build the alternative distribution by bootstrapping from each group separately.
alt_stats <- replicate(n_bootstrap, {
s1 <- sample(x1, size = n, replace = TRUE)
s2 <- sample(x2_shifted, size = n, replace = TRUE)
TwoSample_test_statistic(s1, s2)
})
# Calculate the proportion of alternative test statistics that fall outside the null critical values
results[j] <- mean(alt_stats < crit[1] | alt_stats > crit[2])
}
return(results)
}
# Set seed for reproducibility
set.seed(123)
# Simulate data for two groups (both drawn from N(0,1))
x1 <- rnorm(10, mean = 0, sd = 1)
x2 <- rnorm(10, mean = 0, sd = 1)
# Define bootstrap parameters
alpha <- 0.05
n_bootstrap <- 1000   # Number of bootstrap replicates (increase for more precise estimates)
sample_sizes <- c(10, 20, 30, 50)  # Different sample sizes to test
# Calculate empirical Type I error rates
type1_error <- bootstrap_two_sample(x1, x2, effect_size = 0, alpha = alpha,
n_bootstrap = n_bootstrap, sample_size = sample_sizes)
print("Estimated Type I Error Rates:")
print(type1_error)
# Using the same simulated data from above, now with a true effect of 0.5
effect_size <- 0.75
# Calculate empirical power
power_estimate <- bootstrap_two_sample(x1, x2, effect_size = effect_size, alpha = alpha,
n_bootstrap = n_bootstrap, sample_size = sample_sizes)
bootstrap_two_sample <- function(x1, x2, effect_size, alpha, n_bootstrap, sample_size) {
results <- numeric(length(sample_size))
combined <- c(x1, x2)
for(j in seq_along(sample_size)) {
n <- sample_size[j]
# Null distribution
null_stats <- replicate(n_bootstrap, {
s1 <- sample(combined, n, replace = TRUE)
s2 <- sample(combined, n, replace = TRUE)
TwoSample_test_statistic(s1, s2)
})
crit <- quantile(null_stats, c(alpha/2, 1 - alpha/2))
# Alternative distribution
alt_stats <- replicate(n_bootstrap, {
s1 <- sample(x1, n, replace = TRUE)
s2 <- sample(x2, n, replace = TRUE) + effect_size
TwoSample_test_statistic(s1, s2)
})
results[j] <- mean(alt_stats < crit[1] | alt_stats > crit[2])
}
return(results)
}
bootstrap_two_sample(rnorm(10), rnorm(10), effect_size = 0.5, alpha = 0.05, n_bootstrap = 1000, sample_size = c(10, 20, 30, 50))
bootstrap_two_sample(rnorm(10), rnorm(10), effect_size = 0.0, alpha = 0.05, n_bootstrap = 1000, sample_size = c(10, 20, 30, 50))
bootstrap_two_sample(rnorm(10), rnorm(10), effect_size = 0.0, alpha = 0.05, n_bootstrap = 1000, sample_size = c(10, 20, 30, 50))
bootstrap_two_sample(rnorm(10), rnorm(10), effect_size = 0.0, alpha = 0.05, n_bootstrap = 1000, sample_size = c(10, 20, 30, 50))
bootstrap_two_sample(rnorm(10), rnorm(10), effect_size = 0.0, alpha = 0.05, n_bootstrap = 1000, sample_size = c(10, 20, 30, 50))
bootstrap_two_sample(rnorm(10), rnorm(10), effect_size = 0.0, alpha = 0.05, n_bootstrap = 1000, sample_size = c(10, 20, 30, 50))
bootstrap_two_sample(rnorm(10), rnorm(10), effect_size = 0.0, alpha = 0.05, n_bootstrap = 1000, sample_size = c(10, 20, 30, 50))
bootstrap_two_sample_test <- function(x, y, test, effect_size, alpha, n_bootstrap, sample_size) {
purrr::map_dbl(sample_size, ~{
mean(replicate(n_bootstrap, {
sample_x <- sample(x, .x, replace = TRUE)
sample_y <- sample(y, .x, replace = TRUE) + effect_size
TwoSample.test(sample_x, sample_y, test, alpha, B = 100) < alpha
}))
})
}
bootstrap_two_sample_test(rnorm(10), rnorm(10), effect_size = 0.0, alpha = 0.05, n_bootstrap = 1000, sample_size = c(10, 20, 30)
bootstrap_two_sample_test(rnorm(10), rnorm(10), effect_size = 0.0, alpha = 0.05, n_bootstrap = 1000, sample_size = c(10, 20, 30)
bootstrap_two_sample_test(rnorm(10), rnorm(10), test= "t", effect_size = 0.0, alpha = 0.05, n_bootstrap = 1000, sample_size = c(10, 20, 30)
