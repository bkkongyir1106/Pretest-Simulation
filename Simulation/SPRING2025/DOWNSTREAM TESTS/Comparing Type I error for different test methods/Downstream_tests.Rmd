---
title: "Downstream Test Procedures"
author: "Benedict Kongyir"
date: "`r format(Sys.time(), '%m/%d/%Y')`"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.height = 12, fig.width = 12, warning = FALSE, message = FALSE, verbose = FALSE)

rm(list = ls())
setwd("/Users/benedictkongyir/Desktop/OSU/Research/Pretest-Simulation/Simulation/SPRING2025/DOWNSTREAM TESTS")
source("~/Desktop/OSU/Research/Pretest-Simulation/functions/User_defined_functions.R")
source("~/Desktop/OSU/Research/Pretest-Simulation/functions/utility.R")

if(!require("pacman")) install.packages("pacman")
pacman::p_load(tibble, ggplot2, dplyr, tidyr, foreach,doParallel , parallel, doSNOW)

```

### Simulation setup


```{r}
{
  N <- 1e4;  alpha <- 0.05
  dist_sum <- c("Normal", "Uniform", "t", "Contaminated","Laplace","Exponential", "Chi-Square", "Gamma", "Weibull", "LogNormal",  "Pareto")
  sample_size <- c(8, 10, 15, 20, 25, 30)
  sig_level <- c(0.05)
  effect_size <- 0.5
}
```


## One Sample Case

### One Sample Unconditional Case

```{r}
# # -------------- One Sample Unconditional t-test --------------
# # set up cores for parallel processing
# par_set <- function(cores_reserve = 2)
# {
#   cores = parallel::detectCores()
#   cores_use <- cores - cores_reserve
#   if(Sys.info()["sysname"] == "Windows"){
#     cl <- parallel::makeCluster(cores_use)
#     doParallel::registerDoParallel(cl)
#   }else{
#     cl <- snow::makeSOCKcluster(cores_use)
#     doSNOW::registerDoSNOW(cl)
#   }
#   foreach::getDoParWorkers()
#   return(cl)
# }
# 
# close_cluster <- function(cl) {
#   parallel::stopCluster(cl)
# }
# 
# # Cluster setup
# {
#   my_cl <- par_set(cores_reserve = 2)
# }
# system.time({
#   sim_out <- foreach(n = sample_size,
#                      .packages = c("LaplacesDemon", "VGAM")) %:%
#     foreach(dist = dist_sum)%dopar%
#     {
#       set.seed(12345)
#       error_pval <- power_pval <- numeric(N)
#       for (i in 1:N) {
#         x <- generate_data(n, dist)
#         error_pval[i] <- t.test(x)$p.value
#         power_pval[i] <- t.test(x + effect_size)$p.value
#       }
#       error    <- mean(error_pval < alpha)
#       power    <- mean(power_pval < alpha)
# 
#       results <- list(error = error,
#                       power = power)
#     }
# 
#  # Organize Results in tables
# datavec <- numeric(length(sample_size) * length(dist_sum))
# Type1error <- Power <- array(datavec, dim = c(length(sample_size), length(dist_sum)), dimnames = list(sample_size, dist_sum))
# for (t in seq_along(sample_size)) {
#   for (j in seq_along(dist_sum)) {
# 
#       Type1error[t, j] <- (sim_out[[t]][[j]]$error)
#       Power[t, j] <- (sim_out[[t]][[j]]$power)
# 
#   }
# }
# })
# 
# # Calculate areas under the Type I error rate curves
# AUPC <- apply(Power, 2, compute_area, x = sample_size)
# AUTEC <- apply(Type1error, 2, compute_area, x = sample_size)
# ### Close Cluster
# close_cluster(my_cl)
```


### Results for One Sample Unconditional Case
```{r}
# save(var_name = Power, file = "OneSample.Uncond.power.RData")
# save(var_name = Type1error, file = "OneSample.Uncond.Type1error.RData")

```


<!-- <!-- ### Results for One Sample Unconditional Case --> -->
<!-- <!-- ```{r} --> -->
<!-- <!-- # Determine variable and file names based on effect_size --> -->
<!-- <!-- if (effect_size == 0) { --> -->
<!-- <!--   var_name <- "One.Sample.Unconditional.TypeI" --> -->
<!-- <!--   file_name <- "One.Sample.Unconditional.TypeI.RData" --> -->
<!-- <!-- } else { --> -->
<!-- <!--   var_name <- "One.Sample.Unconditional.Power" --> -->
<!-- <!--   file_name <- "One.Sample.Unconditional.Power.RData" --> -->
<!-- <!-- } --> -->

<!-- <!-- assign(var_name, result_array) --> -->
<!-- <!-- save(list = c("sample_size", "N", var_name), file = file_name) --> -->
<!-- <!-- # print results --> -->
<!-- <!-- cat("Results for:", var_name, "\n") --> -->
<!-- <!-- print(result_array) --> -->
<!-- <!-- ``` --> -->


### One Sample Two-Stage Case

```{r}
# # set up cores for parallel processing
# par_set <- function(cores_reserve = 2)
# {
#   cores = parallel::detectCores()
#   cores_use <- cores - cores_reserve
#   if(Sys.info()["sysname"] == "Windows"){
#     cl <- parallel::makeCluster(cores_use)
#     doParallel::registerDoParallel(cl)
#   }else{
#     cl <- snow::makeSOCKcluster(cores_use)
#     doSNOW::registerDoSNOW(cl)
#   }
#   foreach::getDoParWorkers()
#   return(cl)
# }
#
# close_cluster <- function(cl) {
#   parallel::stopCluster(cl)
# }
#
# # Cluster setup
# {
#   my_cl <- par_set(cores_reserve = 2)
# }
#
# # perform simulation
# system.time({
#   sim_out <- foreach(n = sample_size,
#                      .packages = c("LaplacesDemon", "VGAM")) %:%
#     foreach(dist = dist_sum)%dopar%
#     {
#       set.seed(12345)
#       error_pval <- power_pval <- numeric(N)
#       for(i in 1: N) {
#         x <- generate_data(n, dist)
#         if(shapiro.test(x)$p.value > alpha)
#         {
#           error_pval[i] <- t.test(x)$p.value
#           power_pval[i] <- t.test(x + effect_size)$p.value
#         }else{
#           error_pval[i] <- wilcox.test(x)$p.value
#           power_pval[i] <- wilcox.test(x + effect_size)$p.value
#         }
#       }
#       error    <- mean(error_pval < alpha)
#       power    <- mean(power_pval < alpha)
#
#       results <- list(error = error,
#                       power = power)
#     }
#
#  # Organize Results in tables
# datavec <- numeric(length(sample_size) * length(dist_sum))
# Type1error <- Power <- array(datavec, dim = c(length(sample_size), length(dist_sum)), dimnames = list(sample_size, dist_sum))
# for (t in seq_along(sample_size)) {
#   for (j in seq_along(dist_sum)) {
#
#       Type1error[t, j] <- (sim_out[[t]][[j]]$error)
#       Power[t, j] <- (sim_out[[t]][[j]]$power)
#
#   }
# }
# })
#
# ### Close Cluster
# close_cluster(my_cl)
```

### Results for One Sample Two Stage Case
```{r}
# save(var_name = Power, file = "OneSample.2stage.power.RData")
# save(var_name = Type1error, file = "OneSample.2stage.Type1error.RData")
```


### One Sample Conditional Case
```{r}
# # set up cores for parallel processing
# par_set <- function(cores_reserve = 2)
# {
#   cores = parallel::detectCores()
#   cores_use <- cores - cores_reserve
#   if(Sys.info()["sysname"] == "Windows"){
#     cl <- parallel::makeCluster(cores_use)
#     doParallel::registerDoParallel(cl)
#   }else{
#     cl <- snow::makeSOCKcluster(cores_use)
#     doSNOW::registerDoSNOW(cl)
#   }
#   foreach::getDoParWorkers()
#   return(cl)
# }
#
# close_cluster <- function(cl) {
#   parallel::stopCluster(cl)
# }
#
# # Cluster setup
# {
#   my_cl <- par_set(cores_reserve = 2)
# }
#
# # perform simulation
# system.time({
#   sim_out <- foreach(n = sample_size,
#                      .packages = c("LaplacesDemon", "VGAM")) %:%
#     foreach(dist = dist_sum) %dopar%
#     {
#       set.seed(12345)
#       error_pval <- power_pval <- numeric(N)
#       SamplePast = 0
#       TotalSim = 0
#       while (SamplePast < N) {
#         x <- generate_data(n, dist)
#         TotalSim = TotalSim + 1
#         if(shapiro.test(x)$p.value > alpha)
#         {
#           SamplePast = SamplePast + 1
#           error_pval[SamplePast] <- t.test(x)$p.value
#           power_pval[SamplePast] <- t.test(x + effect_size)$p.value
#         }
#       }
#       error    <- mean(error_pval < alpha)
#       power    <- mean(power_pval < alpha)
#
#       results <- list(error = error,
#                       power = power)
#     }
#
#  # Organize Results in tables
# datavec <- numeric(length(sample_size) * length(dist_sum))
# Type1error <- Power <- array(datavec, dim = c(length(sample_size), length(dist_sum)), dimnames = list(sample_size, dist_sum))
# for (t in seq_along(sample_size)) {
#   for (j in seq_along(dist_sum)) {
#
#       Type1error[t, j] <- (sim_out[[t]][[j]]$error)
#       Power[t, j] <- (sim_out[[t]][[j]]$power)
#
#   }
# }
# })
#
# ### Close Cluster
# close_cluster(my_cl)
```


### Results for One Sample Conditional Case
```{r}
# save(var_name = Power, file = "OneSample.cond.power.RData")
# save(var_name = Type1error, file = "OneSample.cond.Type1error.RData")
```

## Two Samples Case

### Two Sample Unconditional
```{r}
# # set up cores for parallel processing
# par_set <- function(cores_reserve = 2)
# {
#   cores = parallel::detectCores()
#   cores_use <- cores - cores_reserve
#   if(Sys.info()["sysname"] == "Windows"){
#     cl <- parallel::makeCluster(cores_use)
#     doParallel::registerDoParallel(cl)
#   }else{
#     cl <- snow::makeSOCKcluster(cores_use)
#     doSNOW::registerDoSNOW(cl)
#   }
#   foreach::getDoParWorkers()
#   return(cl)
# }
#
# close_cluster <- function(cl) {
#   parallel::stopCluster(cl)
# }
#
# # Cluster setup
# {
#   my_cl <- par_set(cores_reserve = 2)
# }
#
# # perform simulation
# system.time({
#   sim_out <- foreach(n = sample_size,
#                      .packages = c("LaplacesDemon", "VGAM")) %:%
#     foreach(dist = dist_sum) %dopar%
#     {
#       set.seed(12345)
#       error_pval <- power_pval <- numeric(N)
#       for (i in 1:N) {
#         x <- generate_data(n, dist)
#         y <- generate_data(n, dist)
#         error_pval[i] <- t.test(x, y)$p.value
#         power_pval[i] <- t.test(x, y + effect_size)$p.value
#       }
#       error    <- mean(error_pval < alpha)
#       power    <- mean(power_pval < alpha)
#
#       results <- list(error = error,
#                       power = power)
#     }
#
#  # Organize Results in tables
# datavec <- numeric(length(sample_size) * length(dist_sum))
# Type1error <- Power <- array(datavec, dim = c(length(sample_size), length(dist_sum)), dimnames = list(sample_size, dist_sum))
# for (t in seq_along(sample_size)) {
#   for (j in seq_along(dist_sum)) {
#
#       Type1error[t, j] <- (sim_out[[t]][[j]]$error)
#       Power[t, j] <- (sim_out[[t]][[j]]$power)
#
#   }
# }
# })
#
# ### Close Cluster
# close_cluster(my_cl)
```

### Results for Two Sample Unconditional
```{r}
# save(var_name = Power, file = "TwoSample.Uncond.power.RData")
# save(var_name = Type1error, file = "TwoSample.Uncond.Type1error.RData")
```


### Two Sample Two-Stage Case

```{r}
# # set up cores for parallel processing
# par_set <- function(cores_reserve = 2)
# {
#   cores = parallel::detectCores()
#   cores_use <- cores - cores_reserve
#   if(Sys.info()["sysname"] == "Windows"){
#     cl <- parallel::makeCluster(cores_use)
#     doParallel::registerDoParallel(cl)
#   }else{
#     cl <- snow::makeSOCKcluster(cores_use)
#     doSNOW::registerDoSNOW(cl)
#   }
#   foreach::getDoParWorkers()
#   return(cl)
# }
#
# close_cluster <- function(cl) {
#   parallel::stopCluster(cl)
# }
#
# # Cluster setup
# {
#   my_cl <- par_set(cores_reserve = 2)
# }
#
# # perform simulation
# system.time({
#   sim_out <- foreach(n = sample_size,
#                      .packages = c("LaplacesDemon", "VGAM")) %:%
#     foreach(dist = dist_sum)%dopar%
#     {
#       set.seed(12345)
#       error_pval <- power_pval <- numeric(N)
#       for(i in 1: N) {
#         x <- generate_data(n, dist)
#         y <- generate_data(n, dist)
#         if(shapiro.test(x)$p.value > alpha/2 & shapiro.test(y)$p.value > alpha/2)
#         {
#          error_pval[i] <- t.test(x, y)$p.value
#           power_pval[i] <- t.test(x, y + effect_size)$p.value
#         }else{
#           error_pval[i] <- wilcox.test(x, y)$p.value
#           power_pval[i] <- wilcox.test(x, y + effect_size)$p.value
#         }
#       }
#       error    <- mean(error_pval < alpha)
#       power    <- mean(power_pval < alpha)
#
#       results <- list(error = error,
#                       power = power)
#     }
#
#  # Organize Results in tables
# datavec <- numeric(length(sample_size) * length(dist_sum))
# Type1error <- Power <- array(datavec, dim = c(length(sample_size), length(dist_sum)), dimnames = list(sample_size, dist_sum))
# for (t in seq_along(sample_size)) {
#   for (j in seq_along(dist_sum)) {
#
#       Type1error[t, j] <- (sim_out[[t]][[j]]$error)
#       Power[t, j] <- (sim_out[[t]][[j]]$power)
#
#   }
# }
# })
#
# ### Close Cluster
# close_cluster(my_cl)
```

### Results for Two Sample Two Stage Case
```{r}
# save(var_name = Power, file = "TwoSample.2stage.power.RData")
# save(var_name = Type1error, file = "TwoSample.2stage.Type1error.RData")
```


### Two Sample Conditional Case
```{r}
# # set up cores for parallel processing
# par_set <- function(cores_reserve = 2)
# {
#   cores = parallel::detectCores()
#   cores_use <- cores - cores_reserve
#   if(Sys.info()["sysname"] == "Windows"){
#     cl <- parallel::makeCluster(cores_use)
#     doParallel::registerDoParallel(cl)
#   }else{
#     cl <- snow::makeSOCKcluster(cores_use)
#     doSNOW::registerDoSNOW(cl)
#   }
#   foreach::getDoParWorkers()
#   return(cl)
# }
#
# close_cluster <- function(cl) {
#   parallel::stopCluster(cl)
# }
#
# # Cluster setup
# {
#   my_cl <- par_set(cores_reserve = 2)
# }
#
# # perform simulation
# system.time({
#   sim_out <- foreach(n = sample_size,
#                      .packages = c("LaplacesDemon", "VGAM")) %:%
#     foreach(dist = dist_sum) %dopar%
#     {
#       set.seed(12345)
#       error_pval <- power_pval <- numeric(N)
#       SamplePast = 0
#       TotalSim = 0
#       while (SamplePast < N) {
#         x <- generate_data(n, dist)
#         y <- generate_data(n, dist)
#         TotalSim = TotalSim + 1
#         if(shapiro.test(x)$p.value > alpha/2 & shapiro.test(y)$p.value > alpha/2)
#         {
#           SamplePast = SamplePast + 1
#           error_pval[SamplePast] <- t.test(x, y)$p.value
#           power_pval[SamplePast] <- t.test(x, y + effect_size)$p.value
#         }
#       }
#       error    <- mean(error_pval < alpha)
#       power    <- mean(power_pval < alpha)
#
#       results <- list(error = error,
#                       power = power)
#     }
#
#  # Organize Results in tables
# datavec <- numeric(length(sample_size) * length(dist_sum))
# Type1error <- Power <- array(datavec, dim = c(length(sample_size), length(dist_sum)), dimnames = list(sample_size, dist_sum))
# for (t in seq_along(sample_size)) {
#   for (j in seq_along(dist_sum)) {
#
#       Type1error[t, j] <- (sim_out[[t]][[j]]$error)
#       Power[t, j] <- (sim_out[[t]][[j]]$power)
#
#   }
# }
# })
#
# ### Close Cluster
# close_cluster(my_cl)

```

### Results for Two Sample Conditional Case
```{r}
# save(var_name = Power, file = "TwoSample.cond.power.RData")
# save(var_name = Type1error, file = "TwoSample.cond.Type1error.RData")
```

## Data splitting

### Addressing Selection Effects in One Sample Tests
```{r}
# # --------------------Addressing Selection Effects ------------------
# # -------------------- Conditional Type I error ---------------------
# # -------------------------------------------------------------------
# # Set simulation parameters
# set.seed(12345)
# distributions <- c("Normal","Exponential","Chi-Square", "LogNormal")
# sample_size <- c(8, 10, 15, 20, 25, 30, 50)
# N_sim <- 1e4
# alpha <- 0.05
# 
# # Initialize matrices to store results
# initialize_matrix <- function(sample_size, distributions) {
#   matrix(nrow = length(sample_size), ncol = length(distributions),
#          dimnames = list(sample_size, distributions))
# }
# one_sample.type_I_error_data_splitting <- initialize_matrix(sample_size, distributions)
# one_sample_type_I_error_two_stage <- initialize_matrix(sample_size, distributions)
# 
# #---------------------- Data Splitting Procedure ----------------------
# for (j in seq_along(distributions)) {
#   for (i in seq_along(sample_size)) {
#     dist <- distributions[j]
#     n <- sample_size[i]
#     pval_split <- numeric(N_sim)
#     count_split <- 0
#     iter_split <- 0
# 
#     # Simulate until we get N_sim valid cases for data splitting
#     while (count_split < N_sim) {
#       iter_split <- iter_split + 1
#       x <- generate_data(n, dist)
#       split_point <- floor(n/2)
#       first_half <- x[1:split_point]
# 
#       if (shapiro.test(first_half)$p.value > alpha) {
#         count_split <- count_split + 1
#         second_half <- x[(split_point+1):n]
#         pval_split[count_split] <- t.test(second_half)$p.value
#       }
#     }
#     one_sample.type_I_error_data_splitting[i, j] <- mean(pval_split < alpha)
#   }
# }
# 
# #--------------------- Two-Stage Procedure --------------------------
# for (j in seq_along(distributions)) {
#   for (i in seq_along(sample_size)) {
#     dist <- distributions[j]
#     n <- sample_size[i]
#     pval_two_stage <- numeric(N_sim)
#     count_two_stage <- 0
#     iter_two_stage <- 0
# 
#     # Simulate until we get N_sim valid cases for two-stage
#     while (count_two_stage < N_sim) {
#       iter_two_stage <- iter_two_stage + 1
#       x <- generate_data(n, dist)
# 
#       if (shapiro.test(x)$p.value > alpha) {
#         count_two_stage <- count_two_stage + 1
#         pval_two_stage[count_two_stage] <- t.test(x)$p.value
#       }
#     }
#     one_sample_type_I_error_two_stage[i, j] <- mean(pval_two_stage < alpha)
#   }
# }
# 
# save(one_sample.type_I_error_data_splitting,one_sample_type_I_error_two_stage, file = "data_splitting.RData")
```

### One Sample Compare Adaptive Method
```{r}
# set.seed(12345)
# distributions <- c("Normal", "Exponential", "Chi-Square", "LogNormal")
# sample_size <- c(8, 10, 15, 20, 25, 30, 40, 50)
# N_sim <- 1e4
# alpha <- 0.05
# R <- 1e4
# effect_size = 0.0
# 
# # Initialize results matrices
# initialize_matrix <- function(sample_size, distributions) {
#   matrix(nrow = length(sample_size), ncol = length(distributions),
#          dimnames = list(sample_size, distributions))
# }
# 
# one_sample.data_split_boot_error <- initialize_matrix(sample_size, distributions)
# one_sample.direct_method_error <- initialize_matrix(sample_size, distributions)
# one_sample.data_split_perm_error <- initialize_matrix(sample_size, distributions)
# one_sample.adaptive_boot_error <- initialize_matrix(sample_size, distributions)
# one_sample.adaptive_perm_error <- initialize_matrix(sample_size, distributions)
# one_sample_boot_error <- initialize_matrix(sample_size, distributions)
# one_sample_perm_error <- initialize_matrix(sample_size, distributions)
# 
# 
# # Parallel simulation function
# run_simulations <- function(method) {
#   cl <- makeCluster(detectCores() - 1)
#   registerDoParallel(cl)
#   clusterExport(cl, c("generate_data", "bootstrap_one_sample", "OneSample.test", "OneSample_test_statistic", "alpha", "R", "effect_size"))
# 
#   result_matrix <- initialize_matrix(sample_size, distributions)
# 
#   for (j in seq_along(distributions)) {
#     for (i in seq_along(sample_size)) {
#       n <- sample_size[i]
#       dist <- distributions[j]
# 
#       pvals <- foreach(k = 1:N_sim, .combine = c, .packages = "stats") %dopar% {
#         x <- generate_data(n, dist)
# 
#         switch(method,
#                "direct_method" = {
#                  OneSample.test(x, test = "t", alpha = 0.05, effect_size = effect_size, B = R)
#                },
#                "data_split_boot" = {
#                  split_point <- floor(n/2)
#                  part1 <- x[1:split_point]
#                  part2 <- x[(split_point+1):n]
# 
#                  if (shapiro.test(part1)$p.value > alpha) {
#                    OneSample.test(part2, test = "t", alpha = 0.05, effect_size = effect_size, B = R)
#                  } else {
#                    bootstrap_one_sample(part2, effect_size = effect_size, B = R)
#                  }
#                },
#                "data_split_perm" = {
#                  split_point <- floor(n/2)
#                  part1 <- x[1:split_point]
#                  part2 <- x[(split_point+1):n]
# 
#                  if (shapiro.test(part1)$p.value > alpha) {
#                    OneSample.test(part2, test = "t", alpha = 0.05, effect_size = effect_size, B = R)
#                  } else {
#                    OneSample.test(part2, test = "perm", alpha = 0.05, effect_size = effect_size, B = R)
#                  }
#                },
#                "two_stage_boot" = {
#                  if (shapiro.test(x)$p.value > alpha) {
#                    OneSample.test(x, test = "t", alpha = 0.05, effect_size = effect_size, B = R)
#                  } else {
#                    bootstrap_one_sample(x, effect_size = effect_size, B = R)
#                  }
#                },
#                "two_stage_perm" = {
#                  if (shapiro.test(x)$p.value > alpha) {
#                    OneSample.test(x, test = "t", alpha = 0.05, effect_size = effect_size, B = R)
#                  } else {
#                    OneSample.test(x, test = "perm", alpha = 0.05, effect_size = effect_size, B = R)
#                  }
#                },
#                "bootstrap" = {
#                  bootstrap_one_sample(x , effect_size = effect_size, B = R)
#                },
# 
#                "perm" = {
#                  OneSample.test(x, "perm", alpha = 0.05, effect_size = effect_size, B = R)
#                }
#         )
#       }
# 
#       result_matrix[i, j] <- mean(pvals < alpha)
#       cat(sprintf("%s: %s, n=%d completed\n", method, dist, n))
#     }
#   }
# 
#   stopCluster(cl)
#   return(result_matrix)
# }
# 
# # ---------------------------- EXECUTION ----------------------------------------
# # Run all methods in parallel
# one_sample.direct_method_error <- run_simulations("direct_method")
# one_sample.data_split_boot_error <- run_simulations("data_split_boot")
# one_sample.data_split_perm_error <- run_simulations("data_split_perm")
# one_sample.adaptive_boot_error <- run_simulations("two_stage_boot")
# one_sample.adaptive_perm_error <- run_simulations("two_stage_perm")
# one_sample_boot_error <- run_simulations("bootstrap")
# one_sample_perm_error <- run_simulations("perm")
# 
# #---------------------------- SAVE RESULTS -------------------------------------
# save(one_sample.direct_method_error, one_sample.data_split_boot_error,  one_sample.data_split_perm_error, one_sample.adaptive_boot_error,
# one_sample.adaptive_perm_error, one_sample_boot_error, one_sample_perm_error, file = "one_sample.adaptive_type_I_error.RData")

```


### Two Sample Compare Adaptive Method
```{r}
# set.seed(12345)
# distributions <- c("Normal", "Exponential", "Chi-Square", "LogNormal")
# sample_size <- c(8, 10, 15, 20, 25, 30, 40, 50)
# N_sim <- 1e4
# alpha <- 0.05
# R <- 1e4
# effect_size = 0.0
# 
# # Initialize results matrices
# initialize_matrix <- function(sample_size, distributions) {
#                             matrix(nrow = length(sample_size), ncol = length(distributions),
#                             dimnames = list(sample_size, distributions))
# }
# 
# two_sample.direct_method_error <- initialize_matrix(sample_size, distributions)
# two_sample.data_split_boot_error <- initialize_matrix(sample_size, distributions)
# two_sample.data_split_perm_error <- initialize_matrix(sample_size, distributions)
# two_sample.adaptive_boot_error <- initialize_matrix(sample_size, distributions)
# two_sample.adaptive_perm_error <- initialize_matrix(sample_size, distributions)
# two_sample_boot_error <- initialize_matrix(sample_size, distributions)
# two_sample_perm_error <- initialize_matrix(sample_size, distributions)
# 
# # Parallel simulation function
# run_simulations <- function(method) {
#   cl <- makeCluster(detectCores() - 1)
#   registerDoParallel(cl)
#   clusterExport(cl, c("generate_data", "bootstrap_two_sample", "TwoSample.test", "TwoSample_test_statistic", "alpha", "R", "effect_size"))
#   
#   result_matrix <- initialize_matrix(sample_size, distributions)
#   
#   for (j in seq_along(distributions)) {
#     for (i in seq_along(sample_size)) {
#       n <- sample_size[i]
#       dist <- distributions[j]
#       
#       pvals <- foreach(k = 1:N_sim, .combine = c, .packages = "stats") %dopar% {
#         x <- generate_data(n, dist)
#         y <- generate_data(n, dist)
#         switch(method,
#                "direct_method" = {
#                  TwoSample.test(x, y, test = "t", alpha = 0.05, effect_size = effect_size, B = NULL)
#                },
#                "data_split_boot" = {
#                  split_point <- floor(n/2)
#                  x.part1 <- x[1:split_point]
#                  x.part2 <- x[(split_point+1):n]
#                  y.part1 <- y[1:split_point]
#                  y.part2 <- y[(split_point+1):n]
#                  
#                  if (shapiro.test(x.part1)$p.value > alpha & shapiro.test(y.part1)$p.value > alpha) {
#                    TwoSample.test(x.part2, y.part2, test = "t", alpha = 0.05, effect_size = effect_size, B = NULL)
#                  } else {
#                    bootstrap_two_sample(x.part2, y.part2, effect_size = effect_size, B = R)
#                  }
#                },
#                "data_split_perm" = {
#                  split_point <- floor(n/2)
#                  x.part1 <- x[1:split_point]
#                  x.part2 <- x[(split_point+1):n]
#                  y.part1 <- y[1:split_point]
#                  y.part2 <- y[(split_point+1):n]
#                  
#                   if (shapiro.test(x.part1)$p.value > alpha & shapiro.test(y.part1)$p.value > alpha) {
#                    TwoSample.test(x.part2, y.part2, test = "t", alpha = 0.05, effect_size = effect_size, B = NULL)
#                  } else {
#                    TwoSample.test(x.part2, y.part2, test = "perm", alpha = 0.05, effect_size = effect_size, B = R)
#                  }
#                },
#                "two_stage_boot" = {
#                  if (shapiro.test(x)$p.value > alpha & shapiro.test(y)$p.value > alpha) {
#                    TwoSample.test(x, y, test = "t", alpha = 0.05, effect_size = effect_size, B = NULL)
#                  } else {
#                    bootstrap_two_sample(x, y, effect_size = effect_size, B = R)
#                  }
#                },
#                "two_stage_perm" = {
#                  if (shapiro.test(x)$p.value > alpha & shapiro.test(y)$p.value > alpha) {
#                    TwoSample.test(x, y, test = "t", alpha = 0.05, effect_size = effect_size, B = NULL)
#                  } else {
#                    TwoSample.test(x, y,  test = "perm", alpha = 0.05, effect_size = effect_size, B = R)
#                  }
#                },
#                "bootstrap" = {
#                  bootstrap_two_sample(x, y, effect_size = effect_size, B = R)
#                },
#       
#                "perm" = {
#                  TwoSample.test(x, y,  test = "perm", alpha = 0.05, effect_size = effect_size, B = R)
#                }
#         )
#       }
#       
#       result_matrix[i, j] <- mean(pvals < alpha)
#       cat(sprintf("%s: %s, n=%d completed\n", method, dist, n))
#     }
#   }
#   
#   stopCluster(cl)
#   return(result_matrix)
# }
# 
# # ---------------------------- EXECUTION ----------------------------------------
# # Run all methods in parallel
# two_sample.direct_method_error <- run_simulations("direct_method")
# two_sample.data_split_boot_error <- run_simulations("data_split_boot")
# two_sample.data_split_perm_error <- run_simulations("data_split_perm")
# two_sample.adaptive_boot_error <- run_simulations("two_stage_boot")
# two_sample.adaptive_perm_error <- run_simulations("two_stage_perm")
# two_sample_boot_error <- run_simulations("bootstrap")
# two_sample_perm_error <- run_simulations("perm")
# 
# # ---------------------------- SAVE RESULTS -------------------------------------
# save(two_sample.direct_method_error, two_sample.data_split_boot_error,  two_sample.data_split_perm_error, two_sample.adaptive_boot_error,
# two_sample.adaptive_perm_error, two_sample_boot_error, two_sample_perm_error, file = "two_sample.adaptive_type_I_error_results.RData")

```



### Sample splitting vs two-stage method for one sample test
```{r, fig.height = 6, fig.width = 12, warning = FALSE, message = FALSE}
# load("/Users/benedictkongyir/Desktop/OSU/Research/Pretest-Simulation/Simulation/SPRING2025/DOWNSTREAM TESTS/data_splitting.RData")
# # -------------------- Prepare Data for Plotting ------------------------
# # ------ Parameters ------
# alpha <- 0.05  # Define alpha for reference line
# distributions <- c("Exponential", "LogNormal")  # Target distributions
# sample_size <- c(8, 10, 15, 20, 25, 30, 50)
# 
# # ------ function for formatting data structure ------------------------
# create_df <- function(matrix, method_name) {
#     as.data.frame(matrix) %>%
#     rownames_to_column("SampleSize") %>%
#     pivot_longer(-SampleSize, names_to = "Distribution", values_to = "ErrorRate") %>%
#     mutate(
#       SampleSize = as.numeric(SampleSize),
#       Method = method_name
#     ) %>%
#     filter(Distribution %in% distributions) 
# }
# 
# combined_df <- bind_rows(
#   create_df(one_sample.type_I_error_data_splitting, "Data Splitting"),
#   create_df(one_sample_type_I_error_two_stage, "Two-Stage")
# )
# 
# #------------------------ plot curves ------------------------------------
# ggplot(combined_df, aes(x = SampleSize, y = ErrorRate, color = Method)) +
#   geom_line(linewidth = 0.8) +
#   geom_point(size = 2) +
#   facet_wrap(~ Distribution, ncol = 2, scales = "free_y") +  # Allow different y-axis scales
#   geom_hline(yintercept = alpha, linetype = "dashed", color = "darkred") +
#   scale_x_continuous(breaks = sample_size) +
#   labs(
#     title = "Comparison of Conditional Type I Error Rates",
#     x = "Sample Size",
#     y = "Type I Error Rate",
#     color = "Method"
#   ) +
#   theme_bw() +
#   theme(
#     panel.grid.minor = element_blank(),
#     axis.text.x = element_text(angle = 45, hjust = 1),
#     legend.position = "bottom"
#   )

```

### Sample splitting vs two-stage method for two sample test
```{r, fig.height = 6, fig.width = 12, warning = FALSE, message = FALSE}
# load("/Users/benedictkongyir/Desktop/OSU/Research/Pretest-Simulation/Simulation/SPRING2025/DOWNSTREAM TESTS/tests/twosample.data_splitting.RData")
# # -------------------- Prepare Data for Plotting ------------------------
# # ------ Parameters ------
# alpha <- 0.05  # Define alpha for reference line
# distributions <- c("Exponential", "LogNormal")  # Target distributions
# sample_size <- c(8, 10, 15, 20, 25, 30)
# 
# # ------ Data Preparation ------
# create_df <- function(matrix, method_name) {
#   as.data.frame(matrix) %>%
#     rownames_to_column("SampleSize") %>%
#     pivot_longer(-SampleSize, names_to = "Distribution", values_to = "ErrorRate") %>%
#     mutate(
#       SampleSize = as.numeric(SampleSize),
#       Method = method_name
#     ) %>%
#     filter(Distribution %in% distributions)  # Filter early for efficiency
# }
# 
# combined_df <- bind_rows(
#   create_df(twosample.type_I_error_data_splitting, "Data Splitting"),
#   create_df(twosample.type_I_error_two_stage, "Two-Stage")
# )
# 
# ggplot(combined_df, aes(x = SampleSize, y = ErrorRate, color = Method)) +
#   geom_line(linewidth = 0.8) +
#   geom_point(size = 2) +
#   facet_wrap(~ Distribution, ncol = 3, scales = "free_y") +  # Allow different y-axis scales
#   geom_hline(yintercept = alpha, linetype = "dashed", color = "darkred") +
#   scale_x_continuous(breaks = sample_size) +
#   labs(
#     title = "Comparison of Conditional Type I Error Rates",
#     x = "Sample Size",
#     y = "Type I Error Rate",
#     color = "Method"
#   ) +
#   theme_bw() +
#   theme(
#     panel.grid.minor = element_blank(),
#     axis.text.x = element_text(angle = 45, hjust = 1),
#     legend.position = "bottom"
#   )

```



### Comparison Of One Sample Type I error rate for Different Methods(a)
```{r, fig.height = 8, fig.width = 10, warning = FALSE, message = FALSE}
# # Load the data
# load("/Users/benedictkongyir/Desktop/OSU/Research/Pretest-Simulation/Simulation/SPRING2025/DOWNSTREAM TESTS/tests/OneSample.cond.Type1error.RData")
# oneSample_cond <- data.frame(Type1error)
# 
# load("/Users/benedictkongyir/Desktop/OSU/Research/Pretest-Simulation/Simulation/SPRING2025/DOWNSTREAM TESTS/tests/OneSample.2stage.Type1error.RData")
# oneSample2stage <- data.frame(Type1error)
# 
# load("/Users/benedictkongyir/Desktop/OSU/Research/Pretest-Simulation/Simulation/SPRING2025/DOWNSTREAM TESTS/tests/OneSample.Uncond.Type1error.RData")
# oneSampleUncond <- data.frame(Type1error)
# 
# load("/Users/benedictkongyir/Desktop/OSU/Research/Pretest-Simulation/Simulation/SPRING2025/DOWNSTREAM TESTS/Error/data_splitting.RData")
# data_splitting <- data.frame(type_I_error_data_splitting)
# 
# # Process each dataframe into long format with method
# process_df <- function(df, method_name) {
#   df %>%
#     rownames_to_column("SampleSize") %>%
#     mutate(SampleSize = as.numeric(SampleSize)) %>%
#     pivot_longer(cols = -SampleSize, names_to = "Distribution", values_to = "Value") %>%
#     mutate(Method = method_name)
# }
# 
# # Process all dataframes
# oneSample_cond_long <- process_df(oneSample_cond, "Conditional")
# oneSample2stage_long <- process_df(oneSample2stage, "Two-stage")
# twoSample_cond_long <- process_df(oneSampleUncond, "Unconditional")
# data_splitting_long <- process_df(data_splitting, "data_splitting")
# # Combine data
# combined_data <- bind_rows(oneSample_cond_long, oneSample2stage_long, twoSample_cond_long, data_splitting_long)
# 
# # Filter for target distributions
# selected_distributions <- c("Normal", "Exponential", "Chi.Square", "LogNormal")
# combined_filtered <- combined_data %>% 
#   filter(Distribution %in% selected_distributions)
# 
# # Create the plot
# ggplot(combined_filtered, aes(x = SampleSize, y = Value, color = Method)) +
#   geom_hline(yintercept = 0.05, linetype = "dashed", color = "black", linewidth = 0.7) +  # Add reference line
#   geom_point(size = 2) +
#   geom_line(linewidth = 0.8) +
#   facet_wrap(~Distribution, ncol = 2) +
#   theme_bw() +
#   labs(x = "Sample Size", y = "Type I Error Rate", color = "Method") +
#   scale_x_continuous(breaks = c(8, 10, 15, 20, 25, 30)) +
#   theme(legend.position = "bottom",
#         strip.background = element_rect(fill = "lightgrey"),
#         strip.text = element_text(face = "bold"))
```

### Comparison Of One Sample Type I error rate for Different Methods(b)
```{r, fig.height = 8, fig.width = 10, warning = FALSE, message = FALSE}
load("/Users/benedictkongyir/Desktop/OSU/Research/Pretest-Simulation/Simulation/SPRING2025/DOWNSTREAM TESTS/tests/one_sample.adaptive_type_I_error.RData")
direct_method <- data.frame(one_sample.direct_method_error)
data_split.boot <- data.frame(one_sample.data_split_boot_error)
data_split.perm <- data.frame(one_sample.data_split_perm_error)
adaptive_boot <- data.frame(one_sample.adaptive_boot_error)
adaptive_perm <- data.frame(one_sample.adaptive_perm_error)
boot <- data.frame(one_sample_boot_error)
perm <- data.frame(one_sample_perm_error)



# Process each dataframe into long format with method
process_df <- function(df, method_name) {
  df %>%
    rownames_to_column("SampleSize") %>%
    mutate(SampleSize = as.numeric(SampleSize)) %>%
    pivot_longer(cols = -SampleSize, names_to = "Distribution", values_to = "Value") %>%
    mutate(Method = method_name)
}

# Process all dataframes
data_direct_long <- process_df(direct_method, "direct_method")
data_split.boot_long <- process_df(data_split.boot, "data_split & boot")
data_split.perm_long <- process_df(data_split.perm, "data_split & perm")
adaptive_boot_long <- process_df(adaptive_boot, "adaptive_bootstrap")
adaptive_perm_long <- process_df(adaptive_perm, "adaptive_permutation")
boot_long <- process_df(boot, "bootstrap")
perm_long <- process_df(perm, "permutation")

# Combine data
combined_data <- bind_rows(data_direct_long, data_split.boot_long, data_split.perm_long, adaptive_boot_long, adaptive_perm_long, boot_long, perm_long)

# Filter for target distributions
selected_distributions <- c("Normal", "Exponential", "Chi.Square", "LogNormal")
combined_filtered <- combined_data %>% 
  filter(Distribution %in% selected_distributions)

# Create the plot
# Create the plot with different point shapes
ggplot(combined_filtered, aes(x = SampleSize, y = Value, color = Method)) +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "black", linewidth = 0.7) +
  geom_point(aes(shape = Method), size = 3) +  # Add shape aesthetic
  geom_line(linewidth = 0.8) +
  facet_wrap(~Distribution, ncol = 2) +
  theme_bw() +
  labs(x = "Sample Size", y = "Type I Error Rate", color = "Method", shape = "Method") +
  scale_x_continuous(breaks = c(8, 10, 15, 20, 25, 30, 40, 50)) +
  scale_shape_manual(values = c(16, 17, 15, 3, 4, 8, 18)) +  # Custom shapes
  theme(
    legend.position = "bottom",
    strip.background = element_rect(fill = "lightgrey"),
    strip.text = element_text(face = "bold"),
    legend.key = element_blank()
  ) +
  guides(color = guide_legend(nrow = 2),  # Control legend layout
         shape = guide_legend(nrow = 2))
```


### Comparison Of One Sample Power for Different Test Methods
```{r, fig.height = 8, fig.width = 10, warning = FALSE, message = FALSE}
# # Load the data
# load("/Users/benedictkongyir/Desktop/OSU/Research/Pretest-Simulation/Simulation/SPRING2025/DOWNSTREAM TESTS/tests/OneSample.cond.power.RData")
# oneSample_cond <- data.frame(Power)
# 
# load("/Users/benedictkongyir/Desktop/OSU/Research/Pretest-Simulation/Simulation/SPRING2025/DOWNSTREAM TESTS/tests/OneSample.2stage.power.RData")
# oneSample2stage <- data.frame(Power)
# 
# load("/Users/benedictkongyir/Desktop/OSU/Research/Pretest-Simulation/Simulation/SPRING2025/DOWNSTREAM TESTS/tests/OneSample.Uncond.power.RData")
# oneSampleUncond <- data.frame(Power)
# 
# # load("/Users/benedictkongyir/Desktop/OSU/Research/Pretest-Simulation/Simulation/SPRING2025/DOWNSTREAM TESTS/Error/data_splitting.RData")
# # data_splitting <- data.frame(type_I_error_data_splitting)
# 
# # Process each dataframe into long format with method
# process_df <- function(df, method_name) {
#   df %>%
#     rownames_to_column("SampleSize") %>%
#     mutate(SampleSize = as.numeric(SampleSize)) %>%
#     pivot_longer(cols = -SampleSize, names_to = "Distribution", values_to = "Value") %>%
#     mutate(Method = method_name)
# }
# 
# # Process all dataframes
# oneSample_cond_long <- process_df(oneSample_cond, "Conditional")
# oneSample2stage_long <- process_df(oneSample2stage, "Two-stage")
# twoSample_cond_long <- process_df(oneSampleUncond, "Unconditional")
# #data_splitting_long <- process_df(data_splitting, "data_splitting")
# # Combine data
# combined_data <- bind_rows(oneSample_cond_long, oneSample2stage_long, twoSample_cond_long)
# 
# # Filter for target distributions
# selected_distributions <- c("Normal", "Exponential", "Chi.Square", "LogNormal")
# combined_filtered <- combined_data %>% 
#   filter(Distribution %in% selected_distributions)
# 
# # Create the plot
# ggplot(combined_filtered, aes(x = SampleSize, y = Value, color = Method)) +
#   geom_point(size = 2) +
#   geom_line(linewidth = 0.8) +
#   facet_wrap(~Distribution, ncol = 2) +
#   theme_bw() +
#   labs(x = "Sample Size", y = "Power", color = "Method") +
#   scale_x_continuous(breaks = c(8, 10, 15, 20, 25, 30)) +
#   theme(legend.position = "bottom",
#         strip.background = element_rect(fill = "lightgrey"),
#         strip.text = element_text(face = "bold"))
```

### Comparison Of Two Sample Type I error rate for Different Methods
```{r, fig.height = 8, fig.width = 10, warning = FALSE, message = FALSE}
# # Load the data
# load("/Users/benedictkongyir/Desktop/OSU/Research/Pretest-Simulation/Simulation/SPRING2025/DOWNSTREAM TESTS/tests/TwoSample.cond.Type1error.RData")
# twoSample_cond <- data.frame(Type1error)
# 
# load("/Users/benedictkongyir/Desktop/OSU/Research/Pretest-Simulation/Simulation/SPRING2025/DOWNSTREAM TESTS/tests/TwoSample.2stage.Type1error.RData")
# twoSample2stage <- data.frame(Type1error)
# 
#  load("/Users/benedictkongyir/Desktop/OSU/Research/Pretest-Simulation/Simulation/SPRING2025/DOWNSTREAM TESTS/tests/TwoSample.Uncond.Type1error.RData")
# twoSampleUncond <- data.frame(Type1error)
# 
# load("/Users/benedictkongyir/Desktop/OSU/Research/Pretest-Simulation/Simulation/SPRING2025/DOWNSTREAM TESTS/tests/twosample.data_splitting.RData")
# data_splitting <- data.frame(twosample.type_I_error_data_splitting)
# # Process each dataframe into long format with method
# process_df <- function(df, method_name) {
#   df %>%
#     rownames_to_column("SampleSize") %>%
#     mutate(SampleSize = as.numeric(SampleSize)) %>%
#     pivot_longer(cols = -SampleSize, names_to = "Distribution", values_to = "Value") %>%
#     mutate(Method = method_name)
# }
# 
# # Process all dataframes
# twoSample_cond_long <- process_df(twoSample_cond, "Conditional")
# twoSample2stage_long <- process_df(twoSample2stage, "Two-stage")
# twoSampleUncond_long <- process_df(twoSampleUncond, "Unconditional")
# data_splitting_long <- process_df(data_splitting, "data_splitting")
# # Combine data
# combined_data <- bind_rows(twoSample_cond_long, twoSample2stage_long, twoSampleUncond_long, data_splitting_long)
# 
# # Filter for target distributions
# selected_distributions <- c("Normal", "Exponential", "Chi.Square", "LogNormal")
# combined_filtered <- combined_data %>% 
#   filter(Distribution %in% selected_distributions)
# 
# # Create the plot
# ggplot(combined_filtered, aes(x = SampleSize, y = Value, color = Method)) +
#   geom_hline(yintercept = 0.05, linetype = "dashed", color = "black", linewidth = 0.7) +  # Add reference line
#   geom_point(size = 2) +
#   geom_line(linewidth = 0.8) +
#   facet_wrap(~Distribution, ncol = 2) +
#   theme_bw() +
#   labs(x = "Sample Size", y = "Type I Error Rate", color = "Method") +
#   scale_x_continuous(breaks = c(8, 10, 15, 20, 25, 30)) +
#   theme(legend.position = "bottom",
#         strip.background = element_rect(fill = "lightgrey"),
#         strip.text = element_text(face = "bold"))
```

### Comparison Of Two Sample Type I error rate for Different Methods(b)
```{r, fig.height = 8, fig.width = 10, warning = FALSE, message = FALSE}
load("/Users/benedictkongyir/Desktop/OSU/Research/Pretest-Simulation/Simulation/SPRING2025/DOWNSTREAM TESTS/tests/two_sample.adaptive_type_I_error_results.RData")
direct_method <- data.frame(two_sample.direct_method_error)
data_split.boot <- data.frame(two_sample.data_split_boot_error)
data_split.perm <- data.frame(two_sample.data_split_perm_error)
adaptive_boot <- data.frame(two_sample.adaptive_boot_error)
adaptive_perm <- data.frame(two_sample.adaptive_perm_error)
boot <- data.frame(two_sample_boot_error)
perm <- data.frame(two_sample_perm_error)



# Process each dataframe into long format with method
process_df <- function(df, method_name) {
  df %>%
    rownames_to_column("SampleSize") %>%
    mutate(SampleSize = as.numeric(SampleSize)) %>%
    pivot_longer(cols = -SampleSize, names_to = "Distribution", values_to = "Value") %>%
    mutate(Method = method_name)
}

# Process all dataframes
data_direct_long <- process_df(direct_method, "direct_method")
data_split.boot_long <- process_df(data_split.boot, "data_split & boot")
data_split.perm_long <- process_df(data_split.perm, "data_split & perm")
adaptive_boot_long <- process_df(adaptive_boot, "adaptive_bootstrap")
adaptive_perm_long <- process_df(adaptive_perm, "adaptive_permutation")
boot_long <- process_df(boot, "bootstrap")
perm_long <- process_df(perm, "permutation")

# Combine data
combined_data <- bind_rows(data_direct_long, data_split.boot_long, data_split.perm_long, adaptive_boot_long, adaptive_perm_long, boot_long, perm_long)

# Filter for target distributions
selected_distributions <- c("Normal", "Exponential", "Chi.Square", "LogNormal")
combined_filtered <- combined_data %>% 
  filter(Distribution %in% selected_distributions)

# Create the plot
# Create the plot with different point shapes
ggplot(combined_filtered, aes(x = SampleSize, y = Value, color = Method)) +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "black", linewidth = 0.7) +
  geom_point(aes(shape = Method), size = 3) +  # Add shape aesthetic
  geom_line(linewidth = 0.8) +
  facet_wrap(~Distribution, ncol = 2) +
  theme_bw() +
  labs(x = "Sample Size", y = "Type I Error Rate", color = "Method", shape = "Method") +
  scale_x_continuous(breaks = c(8, 10, 15, 20, 25, 30, 40, 50)) +
  scale_shape_manual(values = c(16, 17, 15, 3, 4, 8, 18)) +  # Custom shapes
  theme(
    legend.position = "bottom",
    strip.background = element_rect(fill = "lightgrey"),
    strip.text = element_text(face = "bold"),
    legend.key = element_blank()
  ) +
  guides(color = guide_legend(nrow = 2),  # Control legend layout
         shape = guide_legend(nrow = 2))
```


### Comparison Of Two Sample Power for Different Methods
```{r, fig.height = 8, fig.width = 10, warning = FALSE, message = FALSE}
# # Load the data
# load("/Users/benedictkongyir/Desktop/OSU/Research/Pretest-Simulation/Simulation/SPRING2025/DOWNSTREAM TESTS/tests/TwoSample.cond.power.RData")
# twoSample_cond <- data.frame(Power)
# 
# load("/Users/benedictkongyir/Desktop/OSU/Research/Pretest-Simulation/Simulation/SPRING2025/DOWNSTREAM TESTS/tests/TwoSample.2stage.power.RData")
# twoSample2stage <- data.frame(Power)
# 
# load("/Users/benedictkongyir/Desktop/OSU/Research/Pretest-Simulation/Simulation/SPRING2025/DOWNSTREAM TESTS/tests/TwoSample.Uncond.power.RData")
# twoSampleUncond <- data.frame(Power)
# 
# # Process each dataframe into long format with method
# process_df <- function(df, method_name) {
#   df %>%
#     rownames_to_column("SampleSize") %>%
#     mutate(SampleSize = as.numeric(SampleSize)) %>%
#     pivot_longer(cols = -SampleSize, names_to = "Distribution", values_to = "Value") %>%
#     mutate(Method = method_name)
# }
# 
# # Process all dataframes
# twoSample_cond_long <- process_df(twoSample_cond, "Conditional")
# twoSample2stage_long <- process_df(twoSample2stage, "Two-stage")
# twoSampleUncond_long <- process_df(twoSampleUncond, "Unconditional")
# 
# # Combine data
# combined_data <- bind_rows(twoSample_cond_long, twoSample2stage_long, twoSampleUncond_long)
# 
# # Filter for target distributions
# selected_distributions <- c("Normal", "Exponential", "Chi.Square", "LogNormal")
# combined_filtered <- combined_data %>% 
#   filter(Distribution %in% selected_distributions)
# 
# # Create the plot
# ggplot(combined_filtered, aes(x = SampleSize, y = Value, color = Method)) +
#   geom_point(size = 2) +
#   geom_line(linewidth = 0.8) +
#   facet_wrap(~Distribution, ncol = 2) +
#   theme_bw() +
#   labs(x = "Sample Size", y = "Power", color = "Method") +
#   scale_x_continuous(breaks = c(8, 10, 15, 20, 25, 30)) +
#   theme(legend.position = "bottom",
#         strip.background = element_rect(fill = "lightgrey"),
#         strip.text = element_text(face = "bold"))
```


### One Sample Compare Test Methods
```{r}
# Load user-defined functions
setwd("/Users/benedictkongyir/Desktop/OSU/Research/Pretest-Simulation/Simulation/SPRING2025/DOWNSTREAM TESTS/Comparing Type I error for different test methods")

source("~/Desktop/OSU/Research/Pretest-Simulation/functions/User_defined_functions.R")

# Set seed and simulation parameters
set.seed(12345)
Nsim <- 1e3
sample_size <- c(8, 10, 15, 20, 25, 30, 35, 40)
distribution <- c("Normal", "Exponential", "LogNormal")
alpha <- 0.05
n_boot <- 1e3
effect_size = 0

# Preallocate matrices to store the type I error rates.
# Rows correspond to sample sizes and columns to distributions.
error.t.test_mat           <- matrix(NA, nrow = length(sample_size), ncol = length(distribution))
error.mw_u.test_mat        <- matrix(NA, nrow = length(sample_size), ncol = length(distribution))
error.t_mw_u.test_mat      <- matrix(NA, nrow = length(sample_size), ncol = length(distribution))
error.split.test_mat       <- matrix(NA, nrow = length(sample_size), ncol = length(distribution))
error.bootstrap.test_mat   <- matrix(NA, nrow = length(sample_size), ncol = length(distribution))
error.t.test_bootstrap.test_mat   <- matrix(NA, nrow = length(sample_size), ncol = length(distribution))

# Parallel setup - use makePSOCKcluster() for both windows and mac
ncores <- parallel::detectCores() - 1
cl <- parallel::makePSOCKcluster(ncores)
registerDoSNOW(cl)

# Set up a progress bar
total_iter <- length(distribution) * length(sample_size)
current_iter <- 0
pb <- txtProgressBar(min = 0, max = total_iter, style = 3)

# Loop over distributions and sample sizes
for (d in seq_along(distribution)) {
  dist_current <- distribution[d]
  for (i in seq_along(sample_size)) {
    n <- sample_size[i]

    # Run simulation iterations in parallel for current combination
    sim_results <- foreach(j = 1:Nsim, .combine = rbind,
                           .export = c("generate_data", "OneSample.test", "bootstrap_one_sample_test")) %dopar% {
      # Generate data for current sample size and distribution
      x <- generate_data(n, dist_current)

      # Perform the various tests and record 1 if p-value < alpha
      c(
        t_test    = as.numeric(OneSample.test(x, test = "t", alpha = alpha, effect_size = effect_size) < alpha),
        wilcox    = as.numeric(OneSample.test(x, test = "Wilcox", alpha = alpha, effect_size = effect_size) < alpha),
        t_wilcox  = as.numeric(OneSample.test(x, test = "t_Wilcox", alpha = alpha, effect_size = effect_size) < alpha),
        split     = as.numeric(OneSample.test(x,  test = "2stage.split", alpha = alpha, effect_size = effect_size) < alpha),
        boot      = bootstrap_one_sample_test(x, effect_size = effect_size, alpha = alpha, n_bootstrap = n_boot),
        t.test_bootstrap.test = if(shapiro.test(x)$p.value > alpha ){
          as.numeric(OneSample.test(x, test = "t", alpha = alpha, effect_size = effect_size) < alpha)
        }else{
          bootstrap_one_sample_test(x, effect_size = effect_size, alpha = alpha, n_bootstrap = n_boot)
        }
      )
    }

    # Calculate type I error rates as the proportion of rejections for each test
    error.t.test_mat[i, d]           <- mean(sim_results[, "t_test"])
    error.mw_u.test_mat[i, d]        <- mean(sim_results[, "wilcox"])
    error.t_mw_u.test_mat[i, d]      <- mean(sim_results[, "t_wilcox"])
    error.split.test_mat[i, d]       <- mean(sim_results[, "split"])
    error.bootstrap.test_mat[i, d]   <- mean(sim_results[, "boot"])
    error.t.test_bootstrap.test_mat[i, d]   <- mean(sim_results[, "t.test_bootstrap.test"])

    # Update progress bar and print a message for the current combination
    current_iter <- current_iter + 1
    setTxtProgressBar(pb, current_iter)
    message(sprintf("Completed: sample size %d, distribution %s", n, dist_current))
  }
}

# Clean up the progress bar and stop the cluster
close(pb)
stopCluster(cl)

# Name the rows and columns of each result matrix
rownames(error.t.test_mat)           <- sample_size
colnames(error.t.test_mat)            <- distribution
rownames(error.mw_u.test_mat)         <- sample_size
colnames(error.mw_u.test_mat)          <- distribution
rownames(error.t_mw_u.test_mat)       <- sample_size
colnames(error.t_mw_u.test_mat)        <- distribution
rownames(error.split.test_mat)        <- sample_size
colnames(error.split.test_mat)         <- distribution
rownames(error.bootstrap.test_mat)    <- sample_size
colnames(error.bootstrap.test_mat)     <- distribution
rownames(error.t.test_bootstrap.test_mat)    <- sample_size
colnames(error.t.test_bootstrap.test_mat)     <- distribution

# Save the results
save(error.t.test_mat, error.mw_u.test_mat, error.t_mw_u.test_mat,
     error.split.test_mat, error.bootstrap.test_mat, error.t.test_bootstrap.test_mat,
     file = "one_sample.compare_type_I_error_results.RData")

```



### Compare Test Methods
```{r}
# Load user-defined functions
setwd("/Users/benedictkongyir/Desktop/OSU/Research/Pretest-Simulation/Simulation/SPRING2025/DOWNSTREAM TESTS/Comparing Type I error for different test methods")

source("~/Desktop/OSU/Research/Pretest-Simulation/functions/User_defined_functions.R")

# Set seed and simulation parameters
set.seed(12345)
Nsim <- 1e2
sample_size <- c(8, 10, 15, 20, 25, 30, 50)
distribution <- c("Normal", "Exponential", "LogNormal")
alpha <- 0.05
n_boot <- 1e2
effect_size = 0.0

# Preallocate matrices to store the type I error rates.
# Rows correspond to sample sizes and columns to distributions.
error.t.test_mat           <- matrix(NA, nrow = length(sample_size), ncol = length(distribution))
error.mw_u.test_mat        <- matrix(NA, nrow = length(sample_size), ncol = length(distribution))
error.t_mw_u.test_mat      <- matrix(NA, nrow = length(sample_size), ncol = length(distribution))
error.split.test_mat       <- matrix(NA, nrow = length(sample_size), ncol = length(distribution))
error.permutation.test_mat <- matrix(NA, nrow = length(sample_size), ncol = length(distribution))
error.bootstrap.test_mat   <- matrix(NA, nrow = length(sample_size), ncol = length(distribution))
error.t.test_perm.test_mat <- matrix(NA, nrow = length(sample_size), ncol = length(distribution))

# Parallel setup - use makePSOCKcluster() for both windows and mac
ncores <- parallel::detectCores() - 1
cl <- parallel::makePSOCKcluster(ncores)
registerDoSNOW(cl)

# Set up a progress bar
total_iter <- length(distribution) * length(sample_size)
current_iter <- 0
pb <- txtProgressBar(min = 0, max = total_iter, style = 3)

# Loop over distributions and sample sizes
for (d in seq_along(distribution)) {
  dist_current <- distribution[d]
  for (i in seq_along(sample_size)) {
    n <- sample_size[i]

    # Run simulation iterations in parallel for current combination
    sim_results <- foreach(j = 1:Nsim, .combine = rbind,
                           .export = c("generate_data", "TwoSample.test", "bootstrap_two_sample_test")) %dopar% {
      # Generate data for current sample size and distribution
      x <- generate_data(n, dist_current)
      y <- generate_data(n, dist_current)

      # Perform the various tests and record 1 if p-value < alpha (or the bootstrap returns rejection indicator)
      c(
        t_test    = as.numeric(TwoSample.test(x, y, test = "t", alpha = alpha, effect_size = effect_size) < alpha),
        wilcox    = as.numeric(TwoSample.test(x, y, test = "Wilcox", alpha = alpha, effect_size = effect_size) < alpha),
        t_wilcox  = as.numeric(TwoSample.test(x, y, test = "t_Wilcox", alpha = alpha, effect_size = effect_size) < alpha),
        split     = as.numeric(TwoSample.test(x, y, test = "2stage.split", alpha = alpha, effect_size = effect_size) < alpha),
        perm      = as.numeric(TwoSample.test(x, y, test = "perm", alpha = alpha, effect_size = effect_size, B = n_boot) < alpha),
        boot      = bootstrap_two_sample_test(x, y, effect_size = effect_size, alpha, n_bootstrap = n_boot, sample_size = n),
        
        t.test_perm.test = if(shapiro.test(x)$p.value > alpha & shapiro.test(y)$p.value > alpha){
          as.numeric(TwoSample.test(x, y, test = "t", alpha = alpha, effect_size = effect_size) < alpha)
        }else{
          as.numeric(TwoSample.test(x, y, test = "perm", alpha = alpha, effect_size = effect_size, B = n_boot) < alpha)
        }
      )
    }

    # Calculate type I error rates as the proportion of rejections for each test
    error.t.test_mat[i, d]           <- mean(sim_results[, "t_test"])
    error.mw_u.test_mat[i, d]        <- mean(sim_results[, "wilcox"])
    error.t_mw_u.test_mat[i, d]      <- mean(sim_results[, "t_wilcox"])
    error.split.test_mat[i, d]       <- mean(sim_results[, "split"])
    error.permutation.test_mat[i, d] <- mean(sim_results[, "perm"])
    error.bootstrap.test_mat[i, d]   <- mean(sim_results[, "boot"])
    error.t.test_perm.test_mat[i, d]   <- mean(sim_results[, "t.test_perm.test"])
    # Update progress bar and print a message for the current combination
    current_iter <- current_iter + 1
    setTxtProgressBar(pb, current_iter)
    message(sprintf("Completed: sample size %d, distribution %s", n, dist_current))
  }
}

# Clean up the progress bar and stop the cluster
close(pb)
stopCluster(cl)

# Name the rows and columns of each result matrix
rownames(error.t.test_mat)           <- sample_size
colnames(error.t.test_mat)            <- distribution
rownames(error.mw_u.test_mat)         <- sample_size
colnames(error.mw_u.test_mat)          <- distribution
rownames(error.t_mw_u.test_mat)       <- sample_size
colnames(error.t_mw_u.test_mat)        <- distribution
rownames(error.split.test_mat)        <- sample_size
colnames(error.split.test_mat)         <- distribution
rownames(error.permutation.test_mat)  <- sample_size
colnames(error.permutation.test_mat)   <- distribution
rownames(error.bootstrap.test_mat)    <- sample_size
colnames(error.bootstrap.test_mat)     <- distribution
rownames(error.t.test_perm.test_mat)    <- sample_size
colnames(error.t.test_perm.test_mat)     <- distribution


# Save the results
save(error.t.test_mat, error.mw_u.test_mat, error.t_mw_u.test_mat,
     error.split.test_mat, error.permutation.test_mat, error.bootstrap.test_mat, error.t.test_perm.test_mat,
     file = "two_sample.compare_type_I_error_results.RData")

```

### Two-sample unconditional test
```{r}
# Load user-defined functions
setwd("/Users/benedictkongyir/Desktop/OSU/Research/Pretest-Simulation/Simulation/SPRING2025/DOWNSTREAM TESTS/Comparing Type I error for different test methods")

source("~/Desktop/OSU/Research/Pretest-Simulation/functions/User_defined_functions.R")

# Set seed and simulation parameters
set.seed(12345)
Nsim <- 1e1  # Consider increasing for actual simulations (e.g., 1e4)
sample_size <- c(8, 10, 15, 20, 25, 30)#, 40, 50)
distribution <- c("Normal", "Exponential", "LogNormal")
alpha <- 0.05

# Parallel setup - use makePSOCKcluster() instead
ncores <- parallel::detectCores() - 1
cl <- parallel::makePSOCKcluster(ncores)  # Explicit PSOCK cluster
registerDoSNOW(cl)

# Progress bar setup
total_iter <- length(sample_size) * length(distribution)
pb <- txtProgressBar(max = total_iter, style = 3)
progress <- function(n) setTxtProgressBar(pb, n)
opts <- list(progress = progress)

# Run simulations
results <- foreach(n = sample_size, .combine = rbind,
                   .export = c("generate_data", "TwoSample.test"),
                   .options.snow = opts) %:%
  foreach(dist = distribution, .combine = c) %dopar% {
    iter <- 0
    pvals <- numeric(Nsim)
    while(iter < Nsim) {
      x <- generate_data(n, dist)
      y <- generate_data(n, dist)
      # Ensure required packages are loaded on workers if needed
      if(shapiro.test(x)$p.value > alpha && shapiro.test(y)$p.value > alpha) {
        iter <- iter + 1
        pvals[iter] <- TwoSample.test(x, y, test = "t", alpha = alpha,
                                      effect_size = 0, B = NULL)
      }
    }
    mean(pvals < alpha)
  }

# Cleanup
close(pb)
stopCluster(cl)

# Format results
rownames(results) <- sample_size
colnames(results) <- distribution
print(results)
```



