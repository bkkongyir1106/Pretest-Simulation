---
title: "Machine Learning Approach to Normality Test"
author: "Benedict Kongyir"
date: "`r format(Sys.time(), '%m/%d/%Y')`"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.height = 12, fig.width = 12, warning = FALSE, message = FALSE, verbose = FALSE)
# Required Libraries
rm(list = ls())
if(!require("pacman")) install.packages("pacman")
pacman::p_load(e1071, tseries, nortest, gbm, lawstat, infotheo, ineq, caret, pROC, ROCR, randomForest, evd, discretization, nnet, ggplot2, keras, dplyr, tidyverse, RRF, reshape2, neuralnet, xgboost, data.table)

# Set directories 
setwd("/Users/benedictkongyir/Desktop/OSU/Research/Pretest-Simulation/Simulation/MACHINE LEARNING APPROACH")

# Read-in-external user-defined functions
source("~/Desktop/OSU/Research/Pretest-Simulation/Simulation/SPRING2025/ML Models/fun.R")
```



```{r}

# Zero-crossing rate
calculate_zero_crossing_rate <- function(samples) {
  signs <- samples > 0
  zero_crossings <- sum(abs(diff(signs)))
  zero_crossing_rate <- zero_crossings / (length(samples) - 1)
  return(zero_crossing_rate)
}

# GINI Coefficient 
calculate_gini_coefficient <- function(samples) {
  samples_abs <- abs(samples - min(samples))  # Shift to non-negative
  gini_value <- ineq(samples_abs, type = "Gini")
  return(gini_value)
}

# Outliers
calculate_outliers <- function(samples) {
  qnt <- quantile(samples, probs = c(0.25, 0.75))
  H <- 1.5 * IQR(samples)
  outliers <- sum(samples < (qnt[1] - H) | samples > (qnt[2] + H))
  return(outliers)
}

# SW test
calculate_shapiro_wilk <- function(samples) {
  shapiro_stat <- shapiro.test(samples)$statistic
  return(shapiro_stat)
}

# Shapiro-Francia Test
calculate_shapiro_francia <- function(samples) {
  SF.test <- lawstat::sf.test(samples)$statistic
  return(as.numeric(SF.test))
}

# Liliefors Test 
calculate_lilliefors <- function(samples) {
  LF.test <- nortest::lillie.test(samples)$statistic
  return(as.numeric(LF.test))
}

# Cramer-von Mises Test
calculate_cramer_von_mises <- function(samples) {
  CVM.test <- nortest::cvm.test(samples)$statistic
  return(as.numeric(CVM.test))
}

# Entropy
calculate_entropy <- function(samples) {
  entropy_value <- infotheo::entropy(discretize(samples, nbins = 10))
  return(entropy_value)
}

# Mean Absolute Deviation
calculate_mad <- function(samples) {
  mad_value <- mean(abs(samples - mean(samples)))
  return(mad_value)
}

# Peak-to-Trough Ratio
calculate_peak_to_trough <- function(samples) {
  peak_to_trough_ratio <- max(samples) / abs(min(samples))
  return(peak_to_trough_ratio)
}

# Sample size
calculate_sample_size <- function(samples) {
  return(length(samples))
}

# Range
calculate_range <- function(samples) {
  return(max(samples) - min(samples))
}

# CV
calculate_cv <- function(samples) {
  return(sd(samples) / mean(samples))
}

# Energy Sum of squares
calculate_energy <- function(samples) {
  return(sum(samples^2))
}

calculate_features <- function(samples) {
  skewness <- e1071::skewness(samples)
  kurtosis <- e1071::kurtosis(samples)
  jb_stat <- tseries::jarque.bera.test(samples)$statistic
  ad_stat <- nortest::ad.test(samples)$statistic
  zero_crossing_rate <- calculate_zero_crossing_rate(samples)
  gini_coefficient <- calculate_gini_coefficient(samples)
  outliers <- calculate_outliers(samples)
  shapiro_wilk <- calculate_shapiro_wilk(samples)
  lilliefors_stat <- calculate_lilliefors(samples)
  cramer_von_mises <- calculate_cramer_von_mises(samples)
  sample_size <- calculate_sample_size(samples)
  range <- calculate_range(samples)
  cv <- calculate_cv(samples)
  energy <- calculate_energy(samples)
  entropy <- calculate_entropy(samples)
  peak_trough <- calculate_peak_to_trough(samples)
  mad_deviation <- calculate_mad(samples)
  
  features <- data.frame(
    Skewness = skewness,
    Kurtosis = kurtosis,
    JB_Statistic = as.numeric(jb_stat),
    AD_Statistic = as.numeric(ad_stat),
    Zero_Crossing_Rate = zero_crossing_rate,
    Outliers = outliers,
    Shapiro_Wilk = as.numeric(shapiro_wilk),
    Liliefors = lilliefors_stat,
    Cramer_Von_Mises = cramer_von_mises,
    #Sample_Size = sample_size,
    Range = range,
    Coefficient_of_Variation = cv,
    Energy = energy,
    #Entropy = entropy,
    Peak_trough = peak_trough,
    Mad_deviation = mad_deviation
  )
  
  return(features)
}

# Min-Max normalization function
min_max_normalize <- function(data) {
  return((data - min(data)) / (max(data) - min(data)))
}

# Normalize all numeric columns except the Label column
normalize_data <- function(data) {
  numeric_features <- data[sapply(data, is.numeric)]  # Extract numeric features
  normalized_features <- as.data.frame(lapply(numeric_features, min_max_normalize))  # Normalize features
  normalized_data <- cbind(normalized_features, Label = data$Label)  # Re-attach the Label column
  return(normalized_data)
}

# Step 2: Prepare Data for Machine Learning Models
generate_data <- function(samples_size, N, dist = "normal", label) {
  data <- do.call(rbind, lapply(1:N, function(x) {
    samples <- generate_samples(samples_size, dist)
    features <- calculate_features(samples)
    features$Label <- label
    return(features)
  }))
  return(data)
}

```


```{r}

  # Generate data
  set.seed(12345)
  normal_data <- generate_data(10, 1000, "normal_25", "Normal")
  normal_25 <- generate_data(10, 1000, "normal", "Normal")
  lognormal <- generate_data(10, 200, "LogNormal", "Non_Normal")
  chisq_data <- generate_data(10, 200, "Chi-Square", "Non_Normal")
  exp_data <- generate_data(10, 200, "Exponential", "Non_Normal")
  Weibull <- generate_data(10, 200, "Weibull", "Non_Normal")
  Laplace <- generate_data(10, 200, "Laplace", "Non_Normal")
  Gamma <- generate_data(10, 200, "Gamma", "Non_Normal")
  spike <- generate_data(10, 200, "spike", "Non_Normal")
  cauchy <- generate_data(10, 200, "cauchy", "Non_Normal")
  Uniform <- generate_data(10, 200, "Uniform", "Non_Normal")
  t_3 <- generate_data(10, 200, "t", "Non_Normal")
  t_15 <- generate_data(10, 100, "t_15", "Non_Normal")
  t_25 <- generate_data(10, 100, "t_25", "Non_Normal")
  
  # Combine data
  non_normal_data <- rbind(lognormal, chisq_data, exp_data, Weibull, Laplace, Gamma, spike, cauchy, Uniform, t_3)
  data <- rbind(normal_data,  non_normal_data)
  data$Label <- as.factor(data$Label)
  # Split Data into Training and Test Sets
  set.seed(12345)
  trainIndex <- createDataPartition(data$Label, p = .8, list = FALSE, times = 1)
  train_data <- data[trainIndex, ]
  test_data  <- data[-trainIndex, ]
  train_data <- train_data[sample(nrow(train_data)), ]
  test_data <- test_data[sample(nrow(test_data)), ]
  
  # Normalize the training and test data
  Normalized_train_data <- normalize_data(train_data)
  Normalized_test_data <- normalize_data(test_data)

```

<!-- ### Check correlation of predictors -->
<!-- ```{r} -->
<!-- #remove last column from data frame -->
<!-- df_new <- data[1:(length(data)-1)] -->
<!-- corrplot::corrplot(corr = cor(df_new)) -->
<!-- ``` -->

### Logistics Regression Model
```{r}
# Logistic Regression Model
threshold <- 0.5
# logistic model
log_fit <- glm(formula = Label ~ ., family = binomial, data = Normalized_train_data)

# calculate predicted probabilities for test dataset
Normalized_test_data$target_pred <- predict(log_fit, newdata = Normalized_test_data, type = "response")

# Assign classes to predictions for test dataset
Normalized_test_data$target_pred_class <- ifelse(Normalized_test_data$target_pred >threshold, "Normal", "Non_Normal") %>% as.factor()


# Confusion Matrix
conf_mat_test <- caret::confusionMatrix(data = Normalized_test_data$target_pred_class, reference = Normalized_test_data$Label)

# Print results
print(conf_mat_test)
```

### Logistics Regression Model Data Not Transformed
```{r}
# Logistic Regression Model
threshold <- 0.5
# logistic model
log_fit <- glm(formula = Label ~ ., family = binomial, data = train_data)

# calculate predicted probabilities for test dataset
test_data$target_pred <- predict(log_fit, newdata = test_data, type = "response")

# Assign classes to predictions for test dataset
test_data$target_pred_class <- ifelse(test_data$target_pred >threshold, "Normal", "Non_Normal") %>% as.factor()


# Confusion Matrix
conf_mat_test <- caret::confusionMatrix(data = test_data$target_pred_class, reference = Normalized_test_data$Label)

# Print results
print(conf_mat_test)
```
  

### Random Forest 
```{r}
# Rf model
rf_model <- randomForest(data = Normalized_train_data, Label ~ ., importance = TRUE)
# prediction
Normalized_test_data$rf_pred <- predict(rf_model, newdata = Normalized_test_data)

# create confusion matrices
conf_mat_test <- caret::confusionMatrix(data = Normalized_test_data$rf_pred, reference = Normalized_test_data$Label)
# Print results
print(conf_mat_test)
```

### Random Forest Data not transformed
```{r}
# Rf model
rf_model <- randomForest(data = train_data, Label ~ ., importance = TRUE)
# prediction
test_data$rf_pred <- predict(rf_model, newdata = test_data)

# create confusion matrices
conf_mat_test <- caret::confusionMatrix(data = test_data$rf_pred, reference = test_data$Label)
# Print results
print(conf_mat_test)
```




### Neural Network Model
```{r}
set.seed(12345) 
ann_model <- neuralnet(Label~., 
               data = Normalized_train_data, 
               hidden = 5, 
               err.fct = "ce", 
               linear.output = FALSE, 
               lifesign = 'full', 
               rep = 2, 
               algorithm = "rprop+", 
               stepmax = 1e5) 
```


```{r}
# plot  neural network  
#plot(ann_model, rep = 1) 
```


```{r}
# Set threshold
threshold <- 0.5

# Make predictions using compute()
Normalized_test_data$test_pred_probs <- neuralnet::compute(ann_model, Normalized_test_data[, -which(names(Normalized_test_data) == "Label")])$net.result[,2]

# Assign class labels based on threshold
Normalized_test_data$ann_pred_class <- ifelse(Normalized_test_data$test_pred_probs > threshold, "Normal", "Non_Normal")%>% as.factor()

# Compute Confusion Matrix
conf_mat_test <- caret::confusionMatrix(data = Normalized_test_data$ann_pred_class, reference = Normalized_test_data$Label)

# Print results
print(conf_mat_test)

```

### Neural Network Model data not transformed
```{r}
set.seed(12345) 
ann_model <- neuralnet(Label~., 
               data = train_data, 
               hidden = 5, 
               err.fct = "ce", 
               linear.output = FALSE, 
               lifesign = 'full', 
               rep = 2, 
               algorithm = "rprop+", 
               stepmax = 1e5) 
```


```{r}
# Set threshold
threshold <- 0.5

# Make predictions using compute()
Normalized_test_data$test_pred_probs <- neuralnet::compute(ann_model, Normalized_test_data[, -which(names(Normalized_test_data) == "Label")])$net.result[,2]

# Assign class labels based on threshold
Normalized_test_data$ann_pred_class <- ifelse(Normalized_test_data$test_pred_probs > threshold, "Normal", "Non_Normal")%>% as.factor()

# Compute Confusion Matrix
conf_mat_test <- caret::confusionMatrix(data = Normalized_test_data$ann_pred_class, reference = Normalized_test_data$Label)

# Print results
print(conf_mat_test)

```

### xgboost model
```{r}
# Data Preparation ------------------------------------------------------------
# Get common features (excluding Label)
common_cols <- intersect(
  colnames(Normalized_train_data %>% dplyr::select(-Label)),  # Explicit dplyr::select
  colnames(Normalized_test_data %>% dplyr::select(-Label))    # No extra parenthesis
)

# Prepare training data
train_features <- Normalized_train_data %>% 
  dplyr::select(all_of(common_cols)) %>%  # Use dplyr::select
  mutate(across(everything(), as.numeric)) %>% 
  as.matrix()

train_label <- Normalized_train_data$Label %>% 
  as.factor() %>% 
  as.numeric() - 1  # Convert to 0/1 numeric

# Prepare test data (same structure as training)
test_features <- Normalized_test_data %>% 
  dplyr::select(all_of(common_cols)) %>% 
  mutate(across(everything(), as.numeric)) %>% 
  as.matrix()

test_label <- Normalized_test_data$Label %>% 
  as.factor() %>% 
  as.numeric() - 1

# Model Training & Evaluation (unchanged) -------------------------------------
xgb_model <- xgboost(
  data = train_features,
  label = train_label,
  nrounds = 100,
  max_depth = 4,
  eta = 0.1,
  objective = "binary:logistic",
  eval_metric = "logloss",
  verbose = 0
)

# Prediction & Evaluation -----------------------------------------------------
test_pred_probs <- predict(xgb_model, test_features)
test_pred_labels <- factor(
  ifelse(test_pred_probs > 0.5, "Normal", "Non_Normal"),
  levels = levels(Normalized_test_data$Label)
)

conf_mat_test <- caret::confusionMatrix(
  data = test_pred_labels,
  reference = Normalized_test_data$Label
)

print(conf_mat_test)
```


### xgboost model data not transformed
```{r}
# Data Preparation ------------------------------------------------------------
# Get common features (excluding Label)
common_cols <- intersect(
  colnames(train_data %>% dplyr::select(-Label)),  # Explicit dplyr::select
  colnames(test_data %>% dplyr::select(-Label))    # No extra parenthesis
)

# Prepare training data
train_features <- train_data %>% 
  dplyr::select(all_of(common_cols)) %>%  # Use dplyr::select
  mutate(across(everything(), as.numeric)) %>% 
  as.matrix()

train_label <- train_data$Label %>% 
  as.factor() %>% 
  as.numeric() - 1  # Convert to 0/1 numeric

# Prepare test data (same structure as training)
test_features <- test_data %>% 
  dplyr::select(all_of(common_cols)) %>% 
  mutate(across(everything(), as.numeric)) %>% 
  as.matrix()

test_label <- test_data$Label %>% 
  as.factor() %>% 
  as.numeric() - 1

# Model Training & Evaluation (unchanged) -------------------------------------
xgb_model <- xgboost(
  data = train_features,
  label = train_label,
  nrounds = 100,
  max_depth = 4,
  eta = 0.1,
  objective = "binary:logistic",
  eval_metric = "logloss",
  verbose = 0
)

# Prediction & Evaluation -----------------------------------------------------
test_pred_probs <- predict(xgb_model, test_features)
test_pred_labels <- factor(
  ifelse(test_pred_probs > 0.5, "Normal", "Non_Normal"),
  levels = levels(test_data$Label)
)

conf_mat_test <- caret::confusionMatrix(
  data = test_pred_labels,
  reference = test_data$Label
)

print(conf_mat_test)
```



### ROC Curve
```{r}
log_pred_probs <- predict(log_fit, newdata = Normalized_test_data, type = "response")
rf_pred_probs <- predict(rf_model, newdata = Normalized_test_data, type = "prob")[, 2]
ann_pred_probs <- neuralnet::compute(ann_model, Normalized_test_data[, -which(names(Normalized_test_data) == "Label")])$net.result[,1]
xgb_pred_probs <- predict(xgb_model, test_features)
# convert labels to numeric
Normalized_test_data$Label_binary <- ifelse(Normalized_test_data$Label == "Normal", 1, 0)

# Create ROC objects
roc_log  <- roc(Normalized_test_data$Label_binary, log_pred_probs)
roc_rf   <- roc(Normalized_test_data$Label_binary, rf_pred_probs)
roc_ann  <- roc(Normalized_test_data$Label_binary, ann_pred_probs)
roc_xgb  <- roc(Normalized_test_data$Label_binary, xgb_pred_probs)

# # Plot all ROC curves in a single graph
# ggplot() +
#   geom_line(aes(x = 1 - roc_log$specificities, y = roc_log$sensitivities, color = "Logistic Regression"), size = 1) +
#   geom_line(aes(x = 1 - roc_rf$specificities, y = roc_rf$sensitivities, color = "Random Forest"), size = 1) +
#   geom_line(aes(x = 1 - roc_ann$specificities, y = roc_ann$sensitivities, color = "Neural Network"), size = 1) +
#   geom_line(aes(x = 1 - roc_xgb$specificities, y = roc_xgb$sensitivities, color = "XGBoost"), size = 1) +
#   scale_color_manual(name = "Models", values = c("Logistic Regression" = "blue",
#                                                  "Random Forest" = "green",
#                                                  "Neural Network" = "red",
#                                                  "XGBoost" = "purple")) +
#   labs(title = "ROC Curve Comparison", x = "1 - Specificity (FPR)", y = "Sensitivity (TPR)") +
#   theme_minimal()

```

```{r}
auc_log  <- auc(roc_log)
auc_rf   <- auc(roc_rf)
auc_ann  <- auc(roc_ann)
auc_xgb  <- auc(roc_xgb)

# Print AUC Scores
cat("AUC Scores:\n")
cat("Logistic Regression: ", auc_log, "\n")
cat("Random Forest: ", auc_rf, "\n")
cat("Neural Network: ", auc_ann, "\n")
cat("XGBoost: ", auc_xgb, "\n")

```


## Feature Importance
```{r}
plot_feature_importance_gini <- function(model) {
  feat_importance <- randomForest::importance(model)
  
  # Keep only MeanDecreaseGini and convert to tibble
  feat_importance <- tibble(
    feature = rownames(feat_importance),
    MeanDecreaseGini = feat_importance[, 2] 
  )%>%
    filter(!feature %in% c("target_pred", "target_pred_class", "rf_pred")) 
  #%>%
   # filter(feature %in% c("Skewness", "Kurtosis", "JB_Statistic", "AD_Statistic", "Zero_Crossing_Rate", "Outliers", "Shapiro_Wilk","Liliefors", "Cramer_Von_Mises", "Range", "Coefficient_of_Variation"))
  

  # Order features by Gini importance (highest to lowest)
  feat_importance <- feat_importance %>%
    arrange(MeanDecreaseGini) %>%
    mutate(feature = factor(feature, levels = feature))
  
  ggplot(feat_importance, aes(x = MeanDecreaseGini, y = feature)) +
    geom_col(fill = "#1f77b4") +  
    theme_minimal() +
    labs(title = "Feature Importance (Gini)", 
         x = "Mean Decrease Gini", 
         y = "Features") +
    theme(axis.text.y = element_text(size = 8))
}

# Usage
plot_feature_importance_gini(rf_model)
```
### Harder Tests
```{r}

set.seed(12345)
normal <- generate_data(10, 200, "normal", "Normal")
normal_25 <- generate_data(10, 200, "normal", "Normal")
Uniform <- generate_data(10, 200, "Uniform", "Non_Normal")
Contaminated <- generate_data(10, 200, "Contaminated", "Non_Normal")
Pareto <- generate_data(10, 100, "Pareto", "Non_Normal")
t_data <- generate_data(10, 200, "t", "Non_Normal")
t_15 <- generate_data(10, 200, "t_15", "Non_Normal")
t_25 <- generate_data(10, 200, "t_25", "Non_Normal")
# Combine the validation data
nonnormal.data <- rbind(chisq_data, exp_data)
validation_data <- rbind(normal_25, exp_data)
  validation_data$Label <- as.factor(validation_data$Label)
  # Normalize the training and test data
harder.test_data <- normalize_data(validation_data)

```


```{r}
# # Ensure validation dataset has the same columns as training
# common_cols <- intersect(colnames(Normalized_val_data), colnames(Normalized_val_data))
# 
# # Prepare validation features
# validation_features <- harder.test_data %>%
#   select(all_of(harder.test_data)) %>%
#   select(-Label) %>%
#   mutate(across(everything(), as.numeric)) %>%
#   as.matrix()

# Convert validation labels to factor
validation_labels <- factor(harder.test_data$Label, levels = c("Non_Normal", "Normal"))

```

### Prediction of logistic regression model on vaidation dataset
```{r}
# Predict probabilities
validation_pred_probs_log <- predict(log_fit, newdata = harder.test_data, type = "response")

# Convert probabilities to class labels
validation_pred_class_log <- ifelse(validation_pred_probs_log > 0.5, "Normal", "Non_Normal") %>% as.factor()

# Compute confusion matrix
conf_mat_log <- caret::confusionMatrix(data = validation_pred_class_log, reference = validation_labels)
print(conf_mat_log)

```


### Prediction of random forest model on vaidation dataset
```{r}
# Predict class labels
validation_pred_class_rf <- predict(rf_model, newdata = harder.test_data)

# Compute confusion matrix
conf_mat_rf <- caret::confusionMatrix(data = validation_pred_class_rf, reference = validation_labels)
print(conf_mat_rf)

```


### Prediction of neural network model on vaidation dataset
```{r}
# Get predicted probabilities
validation_pred_probs_ann <- neuralnet::compute(ann_model, harder.test_data[, -which(names(harder.test_data) == "Label")])$net.result[,1]

# Convert probabilities to class labels
validation_pred_class_ann <- ifelse(validation_pred_probs_ann > 0.5, "Normal", "Non_Normal") %>% as.factor()

# Compute confusion matrix
conf_mat_ann <- caret::confusionMatrix(data = validation_pred_class_ann, reference = validation_labels)
print(conf_mat_ann)

```


### Prediction of xgboost model on vaidation dataset
```{r}
# # Get predicted probabilities
# validation_pred_probs_xgb <- predict(xgb_model, validation_features)
# 
# # Convert probabilities to class labels
# validation_pred_class_xgb <- factor(ifelse(validation_pred_probs_xgb > 0.5, "Normal", "Non_Normal"), levels = levels(validation_labels))
# 
# # Compute confusion matrix
# conf_mat_xgb <- caret::confusionMatrix(data = validation_pred_class_xgb, reference = validation_labels)
# print(conf_mat_xgb)

```

